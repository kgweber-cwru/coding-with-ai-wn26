{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/kgweber-cwru/coding-with-ai-wn26/blob/main/week-1-llm-basics-and-api/assignment.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1 Assignment: Your First LLM Application\n",
    "\n",
    "## Objective\n",
    "Build a simple but useful application that solves a real problem in your domain using the Vertex AI API (Gemini).\n",
    "\n",
    "## Requirements\n",
    "1. Use at least 3 different API calls\n",
    "2. Experiment with different parameters (temperature, max_output_tokens)\n",
    "3. Include at least one system instruction\n",
    "4. Track and report the total cost\n",
    "5. Write comments explaining your code\n",
    "\n",
    "## Ideas to Get Started\n",
    "- **Research helper**: Summarize abstracts or generate questions about papers\n",
    "- **Writing assistant**: Check grammar, improve clarity, or adjust tone\n",
    "- **Data analyzer**: Generate insights or explanations from data descriptions\n",
    "- **Teaching tool**: Create quiz questions or explain concepts at different levels\n",
    "- **Email helper**: Draft responses or categorize messages\n",
    "\n",
    "Choose something relevant to YOUR work!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    !pip install -q google-genai google-auth python-dotenv\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "    try:\n",
    "        PROJECT_ID = input(\"Enter your Google Cloud Project ID (press Enter to use default ADC): \").strip()\n",
    "    except Exception:\n",
    "        PROJECT_ID = \"\"\n",
    "    if PROJECT_ID:\n",
    "        os.environ[\"GOOGLE_CLOUD_PROJECT\"] = PROJECT_ID\n",
    "else:\n",
    "    def find_service_account_json(max_up=6):\n",
    "        p = Path.cwd()\n",
    "        for _ in range(max_up):\n",
    "            candidate = p / \"series-2-coding-llms\" / \"creds\"\n",
    "            if candidate.exists():\n",
    "                for f in candidate.glob(\"*.json\"):\n",
    "                    return str(f.resolve())\n",
    "            candidate2 = p / \"creds\"\n",
    "            if candidate2.exists():\n",
    "                for f in candidate2.glob(\"*.json\"):\n",
    "                    return str(f.resolve())\n",
    "            p = p.parent\n",
    "        return None\n",
    "\n",
    "    sa_path = find_service_account_json()\n",
    "    if sa_path:\n",
    "        os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = sa_path\n",
    "    else:\n",
    "        try:\n",
    "            from dotenv import load_dotenv\n",
    "            load_dotenv()\n",
    "        except Exception:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using project: coding-with-ai-wn-26\n",
      "✓ Environment loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import google.auth\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "creds, project = google.auth.default()\n",
    "project = os.environ.get(\"GOOGLE_CLOUD_PROJECT\", project)\n",
    "client = genai.Client(vertexai=True, project=project, location=\"us-central1\")\n",
    "print(f\"Using project: {project}\")\n",
    "\n",
    "print(\"✓ Environment loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Tracking Helper\n",
    "\n",
    "Here's a helpful function from the concepts notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines of thought connect,\n",
      "Logic blooms in code so neat,\n",
      "World awakes to life.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Tokens used: 27\n",
      "Estimated cost: $0.00000870 (or 0.000870 cents)\n"
     ]
    }
   ],
   "source": [
    "# Pricing \n",
    "# Gemini 2.5 Flash Lite ~$0.10 per 1M input tokens, 0.40 per 1M output\n",
    "\n",
    "def estimate_cost(response, model=\"gemini-2.5-flash-lite\"):\n",
    "    \"\"\"Estimate the cost of an API call\"\"\"\n",
    "    # Example pricing (verify at cloud.google.com/vertex-ai/pricing)\n",
    "    pricing = {\n",
    "        \"gemini-2.5-flash-lite\": {\"input\": 0.10, \"output\": 0.40}, \n",
    "        \"gemini-2.5-pro\": {\"input\": 1.25, \"output\": 10}\n",
    "    }\n",
    "    \n",
    "    # Handle unknown models or default\n",
    "    if model not in pricing:\n",
    "        model = \"gemini-2.5-flash-lite\"\n",
    "        \n",
    "    if not response.usage_metadata:\n",
    "        return {\"cost_usd\": 0, \"total_tokens\": 0}\n",
    "\n",
    "    input_tokens = response.usage_metadata.prompt_token_count\n",
    "    output_tokens = response.usage_metadata.candidates_token_count\n",
    "    total_tokens = response.usage_metadata.total_token_count\n",
    "\n",
    "    input_cost = (input_tokens / 1_000_000) * pricing[model][\"input\"]\n",
    "    output_cost = (output_tokens / 1_000_000) * pricing[model][\"output\"]\n",
    "    total_cost = input_cost + output_cost\n",
    "    \n",
    "    return {\n",
    "        \"input_tokens\": input_tokens,\n",
    "        \"output_tokens\": output_tokens,\n",
    "        \"total_tokens\": total_tokens,\n",
    "        \"cost_usd\": total_cost,\n",
    "        \"cost_cents\": total_cost * 100\n",
    "    }\n",
    "\n",
    "# Test it\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash-lite\",\n",
    "    contents=\"Write a haiku about programming.\"\n",
    ")\n",
    "\n",
    "print(response.text)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "cost_info = estimate_cost(response, model=\"gemini-2.5-flash-lite\")\n",
    "print(f\"\\nTokens used: {cost_info['total_tokens']}\")\n",
    "print(f\"Estimated cost: ${cost_info['cost_usd']:.8f} (or {cost_info['cost_cents']:.6f} cents)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documentation\n",
    "\n",
    "Here's documentation for the text API for `google.genai`:\n",
    "\n",
    "https://ai.google.dev/gemini-api/docs/text-generation\n",
    "\n",
    "## Your Question-Answering Service\n",
    "\n",
    "### Step 1: Describe What You're Building\n",
    "Write a markdown cell describing:\n",
    "- What problem does this solve?\n",
    "- Who would use this?\n",
    "- How will it work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOUR DESCRIPTION HERE**\n",
    "\n",
    "I'm building a [describe your application]...\n",
    "\n",
    "It solves the problem of [describe the problem]...\n",
    "\n",
    "It works by [describe your approach]..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Build Your Application\n",
    "Write your code below. Remember to:\n",
    "- Use comments\n",
    "- Track costs\n",
    "- Experiment with parameters\n",
    "- Test with real examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# Example structure:\n",
    "# 1. Define your function(s)\n",
    "# 2. Set up your prompts/system messages\n",
    "# 3. Make API calls\n",
    "# 4. Process and display results\n",
    "# 5. Track costs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Test Your Application\n",
    "Demonstrate your application with real examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test case 1\n",
    "# YOUR TEST HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test case 2\n",
    "# YOUR TEST HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test case 3\n",
    "# YOUR TEST HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Report Your Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display total cost\n",
    "print(f\"\\nTotal Cost Summary\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Total API calls: [YOUR COUNT]\")\n",
    "print(f\"Total cost: ${total_cost:.6f}\")\n",
    "print(f\"Average cost per call: ${total_cost/[NUMBER_OF_CALLS]:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection Questions\n",
    "\n",
    "Answer these questions in markdown cells:\n",
    "\n",
    "### 1. What worked well?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOUR ANSWER HERE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. What was challenging or surprising?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOUR ANSWER HERE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. How did temperature affect your results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOUR ANSWER HERE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. What would you improve or add next?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOUR ANSWER HERE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Challenges (Optional)\n",
    "\n",
    "If you finish early, try these:\n",
    "\n",
    "1. **Compare models**: Run the same task with `gemini-2.5-flash-lite` and `gemini-2.5-pro`. Compare quality and cost.\n",
    "\n",
    "2. **Optimize for cost**: Can you get similar results with fewer tokens? Try:\n",
    "   - Shorter prompts\n",
    "   - Lower max_output_tokens\n",
    "   - More precise system instructions\n",
    "\n",
    "3. **Error handling**: Add try/except blocks to handle API errors gracefully\n",
    "\n",
    "4. **Batch processing**: Adapt your application to process multiple inputs efficiently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BONUS CODE HERE (if attempting)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Checklist\n",
    "\n",
    "Before you submit, make sure you have:\n",
    "- [ ] Described what you built and why\n",
    "- [ ] Made at least 3 API calls with different parameters\n",
    "- [ ] Used at least one system message effectively\n",
    "- [ ] Tested with real examples from your domain\n",
    "- [ ] Tracked and reported total costs\n",
    "- [ ] Commented your code clearly\n",
    "- [ ] Answered all reflection questions\n",
    "- [ ] Saved your notebook!\n",
    "\n",
    "## Next Week Preview\n",
    "\n",
    "Next week, we'll learn how to build conversations that remember context. Bring ideas for chatbot applications you'd like to build!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_seminar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
