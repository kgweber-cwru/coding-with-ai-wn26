{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "if IN_COLAB:\n",
    "    # Install minimal dependencies (quiet)\n",
    "    !pip install -q google-genai google-auth python-dotenv\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "    # Allow students to set project ID (or rely on ADC)\n",
    "    try:\n",
    "        PROJECT_ID = input(\"Enter your Google Cloud Project ID (press Enter to use default ADC): \").strip()\n",
    "    except Exception:\n",
    "        PROJECT_ID = \"\"\n",
    "    if PROJECT_ID:\n",
    "        import os\n",
    "        os.environ[\"GOOGLE_CLOUD_PROJECT\"] = PROJECT_ID\n",
    "\n",
    "# Initialize client (works in Colab and locally)\n",
    "import os\n",
    "import google.auth\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "creds, project = google.auth.default()\n",
    "project = os.environ.get(\"GOOGLE_CLOUD_PROJECT\", project)\n",
    "client = genai.Client(vertexai=True, project=project, location=\"us-central1\")\n",
    "print(f\"Using project: {project}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/kgweber-cwru/coding-with-ai-wn26/blob/main/series-2-coding-llms/week-1-llm-basics-and-api/assignment.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1 Assignment: Your First LLM Application\n",
    "\n",
    "## Objective\n",
    "Build a simple but useful application that solves a real problem in your domain using the Vertex AI API (Gemini).\n",
    "\n",
    "## Requirements\n",
    "1. Use at least 3 different API calls\n",
    "2. Experiment with different parameters (temperature, max_output_tokens)\n",
    "3. Include at least one system instruction\n",
    "4. Track and report the total cost\n",
    "5. Write comments explaining your code\n",
    "\n",
    "## Ideas to Get Started\n",
    "- **Research helper**: Summarize abstracts or generate questions about papers\n",
    "- **Writing assistant**: Check grammar, improve clarity, or adjust tone\n",
    "- **Data analyzer**: Generate insights or explanations from data descriptions\n",
    "- **Teaching tool**: Create quiz questions or explain concepts at different levels\n",
    "- **Email helper**: Draft responses or categorize messages\n",
    "\n",
    "Choose something relevant to YOUR work!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "import google.auth\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "creds, project = google.auth.default()\n",
    "client = genai.Client(vertexai=True, project=project, location=\"us-central1\")\n",
    "\n",
    "print(\"âœ“ Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Tracking Helper\n",
    "Copy this function from the concepts notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_cost(response, model=\"gemini-2.5-flash\"):\n",
    "    \"\"\"Estimate the cost of an API call\"\"\"\n",
    "    # Example pricing (verify at cloud.google.com/vertex-ai/pricing)\n",
    "    pricing = {\n",
    "        \"gemini-2.5-flash\": {\"input\": 0.075, \"output\": 0.30},\n",
    "        \"gemini-1.5-pro\": {\"input\": 3.50, \"output\": 10.50}\n",
    "    }\n",
    "    \n",
    "    if model not in pricing:\n",
    "        model = \"gemini-2.5-flash\"\n",
    "    \n",
    "    if not response.usage_metadata:\n",
    "        return {\"total_tokens\": 0, \"cost_usd\": 0}\n",
    "\n",
    "    input_cost = (response.usage_metadata.prompt_token_count / 1_000_000) * pricing[model][\"input\"]\n",
    "    output_cost = (response.usage_metadata.candidates_token_count / 1_000_000) * pricing[model][\"output\"]\n",
    "    \n",
    "    return {\n",
    "        \"total_tokens\": response.usage_metadata.total_token_count,\n",
    "        \"cost_usd\": input_cost + output_cost\n",
    "    }\n",
    "\n",
    "# Track total cost across all calls\n",
    "total_cost = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Application\n",
    "\n",
    "### Step 1: Describe What You're Building\n",
    "Write a markdown cell describing:\n",
    "- What problem does this solve?\n",
    "- Who would use this?\n",
    "- How will it work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOUR DESCRIPTION HERE**\n",
    "\n",
    "I'm building a [describe your application]...\n",
    "\n",
    "It solves the problem of [describe the problem]...\n",
    "\n",
    "It works by [describe your approach]..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Build Your Application\n",
    "Write your code below. Remember to:\n",
    "- Use comments\n",
    "- Track costs\n",
    "- Experiment with parameters\n",
    "- Test with real examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# Example structure:\n",
    "# 1. Define your function(s)\n",
    "# 2. Set up your prompts/system messages\n",
    "# 3. Make API calls\n",
    "# 4. Process and display results\n",
    "# 5. Track costs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Test Your Application\n",
    "Demonstrate your application with real examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test case 1\n",
    "# YOUR TEST HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test case 2\n",
    "# YOUR TEST HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test case 3\n",
    "# YOUR TEST HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Report Your Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display total cost\n",
    "print(f\"\\nTotal Cost Summary\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Total API calls: [YOUR COUNT]\")\n",
    "print(f\"Total cost: ${total_cost:.6f}\")\n",
    "print(f\"Average cost per call: ${total_cost/[NUMBER_OF_CALLS]:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection Questions\n",
    "\n",
    "Answer these questions in markdown cells:\n",
    "\n",
    "### 1. What worked well?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOUR ANSWER HERE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. What was challenging or surprising?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOUR ANSWER HERE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. How did temperature affect your results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOUR ANSWER HERE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. What would you improve or add next?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOUR ANSWER HERE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Challenges (Optional)\n",
    "\n",
    "If you finish early, try these:\n",
    "\n",
    "1. **Compare models**: Run the same task with `gemini-1.5-flash` and `gemini-1.5-pro`. Compare quality and cost.\n",
    "\n",
    "2. **Optimize for cost**: Can you get similar results with fewer tokens? Try:\n",
    "   - Shorter prompts\n",
    "   - Lower max_output_tokens\n",
    "   - More precise system instructions\n",
    "\n",
    "3. **Error handling**: Add try/except blocks to handle API errors gracefully\n",
    "\n",
    "4. **Batch processing**: Adapt your application to process multiple inputs efficiently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BONUS CODE HERE (if attempting)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Checklist\n",
    "\n",
    "Before you submit, make sure you have:\n",
    "- [ ] Described what you built and why\n",
    "- [ ] Made at least 3 API calls with different parameters\n",
    "- [ ] Used at least one system message effectively\n",
    "- [ ] Tested with real examples from your domain\n",
    "- [ ] Tracked and reported total costs\n",
    "- [ ] Commented your code clearly\n",
    "- [ ] Answered all reflection questions\n",
    "- [ ] Saved your notebook!\n",
    "\n",
    "## Next Week Preview\n",
    "\n",
    "Next week, we'll learn how to build conversations that remember context. Bring ideas for chatbot applications you'd like to build!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
