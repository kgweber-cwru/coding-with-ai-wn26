{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/kgweber-cwru/coding-with-ai-wn26/blob/main/week-3-prompt-engineering/assignment.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 3 Assignment: Build a Prompt Template Library\n",
    "\n",
    "## Objective\n",
    "Create a collection of reusable prompt templates for common tasks in your domain, demonstrating dynamic prompts, few-shot learning, and structured output parsing.\n",
    "\n",
    "## Requirements\n",
    "1. Create at least 3 different prompt templates\n",
    "2. At least one template should use few-shot learning\n",
    "3. At least one template should produce structured (JSON) output\n",
    "4. Demonstrate batch processing with one template\n",
    "5. Include error handling and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    !pip install -q google-genai google-auth python-dotenv numpy\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "    try:\n",
    "        PROJECT_ID = input(\"Enter your Google Cloud Project ID (press Enter to use default ADC): \").strip()\n",
    "    except Exception:\n",
    "        PROJECT_ID = \"\"\n",
    "    if PROJECT_ID:\n",
    "        os.environ[\"GOOGLE_CLOUD_PROJECT\"] = PROJECT_ID\n",
    "else:\n",
    "    def find_service_account_json(max_up=6):\n",
    "        p = Path.cwd()\n",
    "        for _ in range(max_up):\n",
    "            candidate = p / \"series-2-coding-llms\" / \"creds\"\n",
    "            if candidate.exists():\n",
    "                for f in candidate.glob(\"*.json\"):\n",
    "                    return str(f.resolve())\n",
    "            candidate2 = p / \"creds\"\n",
    "            if candidate2.exists():\n",
    "                for f in candidate2.glob(\"*.json\"):\n",
    "                    return str(f.resolve())\n",
    "            p = p.parent\n",
    "        return None\n",
    "\n",
    "    sa_path = find_service_account_json()\n",
    "    if sa_path:\n",
    "        os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = sa_path\n",
    "    else:\n",
    "        try:\n",
    "            from dotenv import load_dotenv\n",
    "            load_dotenv()\n",
    "        except Exception:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using project: coding-with-ai-wn-26\n",
      "✓ Environment loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import google.auth\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "creds, project = google.auth.default()\n",
    "project = os.environ.get(\"GOOGLE_CLOUD_PROJECT\", project)\n",
    "client = genai.Client(vertexai=True, project=project, location=\"us-central1\")\n",
    "print(f\"Using project: {project}\")\n",
    "\n",
    "print(\"✓ Environment loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy Helper Classes\n",
    "You'll need these from the concepts notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PromptTemplate:\n",
    "    \"\"\"Reusable prompt template with validation\"\"\"\n",
    "    \n",
    "    def __init__(self, template, required_vars=None):\n",
    "        self.template = template\n",
    "        self.required_vars = required_vars or []\n",
    "    \n",
    "    def format(self, **kwargs):\n",
    "        missing = [var for var in self.required_vars if var not in kwargs]\n",
    "        if missing:\n",
    "            raise ValueError(f\"Missing required variables: {missing}\")\n",
    "        return self.template.format(**kwargs)\n",
    "    \n",
    "    def run(self, **kwargs):\n",
    "        prompt = self.format(**kwargs)\n",
    "        response = client.models.generate_content(\n",
    "            model=\"gemini-2.5-flash-lite\",\n",
    "            contents=prompt,\n",
    "            config=types.GenerateContentConfig(\n",
    "                temperature=kwargs.get('temperature', 0.3)\n",
    "            )\n",
    "        )\n",
    "        return response.text\n",
    "\n",
    "class PromptLibrary:\n",
    "    def __init__(self):\n",
    "        self.prompts = {}\n",
    "    \n",
    "    def register(self, name, template, required_vars=None):\n",
    "        self.prompts[name] = PromptTemplate(template, required_vars)\n",
    "    \n",
    "    def get(self, name):\n",
    "        if name not in self.prompts:\n",
    "            raise ValueError(f\"Prompt '{name}' not found\")\n",
    "        return self.prompts[name]\n",
    "    \n",
    "    def list(self):\n",
    "        return list(self.prompts.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Prompt Library\n",
    "\n",
    "### Step 1: Describe Your Domain and Use Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOUR DESCRIPTION HERE**\n",
    "\n",
    "My domain: [describe your field]\n",
    "\n",
    "Common tasks I want to automate:\n",
    "1. [task 1]\n",
    "2. [task 2]\n",
    "3. [task 3]\n",
    "\n",
    "Why these templates will be useful: [explain]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create Your Prompt Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize your library\n",
    "my_library = PromptLibrary()\n",
    "\n",
    "# Template 1: [Describe what it does]\n",
    "my_library.register(\n",
    "    \"template_1_name\",\n",
    "    \"\"\"YOUR TEMPLATE HERE\n",
    "    Use {variable_name} for dynamic parts\n",
    "    \"\"\",\n",
    "    required_vars=['list', 'your', 'vars']\n",
    ")\n",
    "\n",
    "# Template 2: [Describe what it does]\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Template 3: [Describe what it does]\n",
    "# YOUR CODE HERE\n",
    "\n",
    "print(f\"Created library with {len(my_library.list())} templates:\")\n",
    "print(my_library.list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Few-Shot Learning Template\n",
    "Create a template that uses examples to guide behavior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FewShotTemplate:\n",
    "    \"\"\"Template with few-shot examples\"\"\"\n",
    "    \n",
    "    def __init__(self, task_description, examples):\n",
    "        self.task_description = task_description\n",
    "        self.examples = examples  # List of (input, output) tuples\n",
    "    \n",
    "    def run(self, new_input):\n",
    "        # Build prompt with examples\n",
    "        prompt = f\"{self.task_description}\\n\\n\"\n",
    "        \n",
    "        for inp, out in self.examples:\n",
    "            prompt += f\"Input: {inp}\\nOutput: {out}\\n\\n\"\n",
    "        \n",
    "        prompt += f\"Input: {new_input}\\nOutput:\"\n",
    "        \n",
    "        response = client.models.generate_content(\n",
    "            model=\"gemini-2.5-flash-lite\",\n",
    "            contents=prompt,\n",
    "            config=types.GenerateContentConfig(\n",
    "                temperature=0\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        return response.text\n",
    "\n",
    "# Create your few-shot template\n",
    "my_fewshot = FewShotTemplate(\n",
    "    task_description=\"YOUR TASK DESCRIPTION\",\n",
    "    examples=[\n",
    "        (\"example input 1\", \"example output 1\"),\n",
    "        (\"example input 2\", \"example output 2\"),\n",
    "        # Add more examples\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Test it\n",
    "result = my_fewshot.run(\"YOUR TEST INPUT\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Structured Output Template\n",
    "Create a template that produces JSON output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_structured_info(text, schema):\n",
    "    \"\"\"Extract structured information according to schema\"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"Extract information from the text according to this schema.\n",
    "    \n",
    "    Schema: {json.dumps(schema, indent=2)}\n",
    "    \n",
    "    Text: {text}\n",
    "    \"\"\"\n",
    "    \n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.5-flash-lite\",\n",
    "        contents=prompt,\n",
    "        config=types.GenerateContentConfig(\n",
    "            temperature=0,\n",
    "            response_mime_type=\"application/json\"\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Parse JSON\n",
    "    try:\n",
    "        return json.loads(response.text)\n",
    "    except json.JSONDecodeError:\n",
    "        content = response.text\n",
    "        start = content.find('{')\n",
    "        end = content.rfind('}') + 1\n",
    "        if start != -1 and end > start:\n",
    "            return json.loads(content[start:end])\n",
    "        raise\n",
    "\n",
    "# Define your schema\n",
    "my_schema = {\n",
    "    \"field1\": \"type\",\n",
    "    \"field2\": \"type\",\n",
    "    # Add your fields\n",
    "}\n",
    "\n",
    "# Test with your data\n",
    "test_text = \"\"\"YOUR TEST TEXT HERE\"\"\"\n",
    "\n",
    "result = extract_structured_info(test_text, my_schema)\n",
    "print(json.dumps(result, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Batch Processing\n",
    "Process multiple items with one of your templates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_process_with_template(items, template_name, **template_kwargs):\n",
    "    \"\"\"Process multiple items using a template from the library\"\"\"\n",
    "    results = []\n",
    "    template = my_library.get(template_name)\n",
    "    \n",
    "    for i, item in enumerate(items, 1):\n",
    "        print(f\"Processing {i}/{len(items)}...\", end=\" \")\n",
    "        \n",
    "        # Prepare kwargs for this item\n",
    "        item_kwargs = template_kwargs.copy()\n",
    "        item_kwargs['input_item'] = item  # Adjust this based on your template\n",
    "        \n",
    "        result = template.run(**item_kwargs)\n",
    "        results.append({\"input\": item, \"output\": result})\n",
    "        print(\"✓\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Test batch processing\n",
    "test_items = [\n",
    "    # YOUR TEST ITEMS\n",
    "]\n",
    "\n",
    "batch_results = batch_process_with_template(\n",
    "    test_items,\n",
    "    \"your_template_name\",\n",
    "    # additional kwargs\n",
    ")\n",
    "\n",
    "# Display results\n",
    "for result in batch_results:\n",
    "    print(f\"\\nInput: {result['input']}\")\n",
    "    print(f\"Output: {result['output']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Error Handling and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def robust_template_execution(template_func, max_retries=2, **kwargs):\n",
    "    \"\"\"Execute template with retry logic\"\"\"\n",
    "    \n",
    "    for attempt in range(max_retries + 1):\n",
    "        try:\n",
    "            result = template_func(**kwargs)\n",
    "            \n",
    "            # Add your validation logic here\n",
    "            # For example: check result is not empty, has expected fields, etc.\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt + 1} failed: {e}\")\n",
    "            if attempt == max_retries:\n",
    "                print(\"Max retries reached, returning None\")\n",
    "                return None\n",
    "            print(\"Retrying...\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Test error handling\n",
    "# YOUR TEST CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstration\n",
    "\n",
    "### Show all your templates in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"PROMPT LIBRARY DEMONSTRATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Demo each template\n",
    "# YOUR DEMONSTRATION CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection Questions\n",
    "\n",
    "### 1. Which template was most useful? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOUR ANSWER**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. What challenges did you face with structured output parsing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOUR ANSWER**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. How did few-shot examples affect output quality?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOUR ANSWER**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. How would you share this library with colleagues?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOUR ANSWER**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Challenges\n",
    "\n",
    "### 1. Save/Load Library\n",
    "Implement methods to save your library to a file and load it later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BONUS CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Template Versioning\n",
    "Add version tracking to your templates so you can A/B test different prompts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BONUS CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Cost Tracking\n",
    "Add token counting and cost estimation to your library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BONUS CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Checklist\n",
    "\n",
    "- [ ] Created at least 3 prompt templates\n",
    "- [ ] Implemented few-shot learning template\n",
    "- [ ] Implemented structured output template\n",
    "- [ ] Demonstrated batch processing\n",
    "- [ ] Added error handling\n",
    "- [ ] Tested all templates with realistic examples\n",
    "- [ ] Answered reflection questions\n",
    "- [ ] Documented each template's purpose\n",
    "\n",
    "## Next Week\n",
    "\n",
    "We'll dive into **embeddings and RAG concepts**:\n",
    "- Vector representations\n",
    "- Semantic similarity\n",
    "- Document search\n",
    "- Preparing for RAG systems"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_seminar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
