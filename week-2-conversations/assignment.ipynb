{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2 Assignment: Build a Conversational Application\n",
    "\n",
    "## Objective\n",
    "Create a conversational application that maintains context across multiple turns and serves a specific purpose in your domain.\n",
    "\n",
    "## Requirements\n",
    "1. Use the Conversation class (or extend it)\n",
    "2. Include a well-crafted system message\n",
    "3. Demonstrate at least 5 conversation turns\n",
    "4. Show how context is maintained across turns\n",
    "5. Track token usage and estimate costs\n",
    "\n",
    "## Ideas\n",
    "- **Research advisor**: Helps refine research questions through dialogue\n",
    "- **Study buddy**: Explains concepts and answers follow-up questions\n",
    "- **Interview bot**: Conducts structured interviews for qualitative research\n",
    "- **Writing coach**: Provides feedback and suggestions iteratively\n",
    "- **Clinical decision support**: Helps work through diagnostic reasoning\n",
    "- **Data analysis helper**: Assists with data interpretation questions\n",
    "- **Grant writing assistant**: Helps develop and refine grant proposals\n",
    "- **Literature review helper**: Discusses papers and synthesizes themes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "print(\"✓ Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy the Conversation Class\n",
    "Use the class from the concepts notebook (or extend it!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conversation:\n",
    "    \"\"\"A simple conversation manager\"\"\"\n",
    "    \n",
    "    def __init__(self, system_message=\"You are a helpful assistant.\", model=\"gpt-4o-mini\"):\n",
    "        self.messages = [{\"role\": \"system\", \"content\": system_message}]\n",
    "        self.model = model\n",
    "        self.total_tokens = 0\n",
    "    \n",
    "    def add_user_message(self, content):\n",
    "        \"\"\"Add a user message to the conversation\"\"\"\n",
    "        self.messages.append({\"role\": \"user\", \"content\": content})\n",
    "    \n",
    "    def get_response(self, temperature=0.7, max_tokens=None):\n",
    "        \"\"\"Get assistant response and add to history\"\"\"\n",
    "        response = client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=self.messages,\n",
    "            temperature=temperature,\n",
    "            max_tokens=max_tokens\n",
    "        )\n",
    "        \n",
    "        assistant_message = response.choices[0].message.content\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": assistant_message})\n",
    "        \n",
    "        self.total_tokens += response.usage.total_tokens\n",
    "        \n",
    "        return assistant_message\n",
    "    \n",
    "    def chat(self, user_message, temperature=0.7, max_tokens=None):\n",
    "        \"\"\"Convenience method: add user message and get response\"\"\"\n",
    "        self.add_user_message(user_message)\n",
    "        return self.get_response(temperature, max_tokens)\n",
    "    \n",
    "    def display_history(self):\n",
    "        \"\"\"Display the conversation history\"\"\"\n",
    "        for msg in self.messages:\n",
    "            role = msg[\"role\"].upper()\n",
    "            content = msg[\"content\"]\n",
    "            print(f\"{role}: {content}\")\n",
    "            print(\"-\" * 50)\n",
    "    \n",
    "    def get_token_count(self):\n",
    "        \"\"\"Get total tokens used\"\"\"\n",
    "        return self.total_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Application\n",
    "\n",
    "### Step 1: Describe Your Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOUR DESCRIPTION HERE**\n",
    "\n",
    "I'm building: [describe your conversational application]\n",
    "\n",
    "Purpose: [what problem does it solve?]\n",
    "\n",
    "Target users: [who would use this?]\n",
    "\n",
    "How it works: [brief explanation of the conversation flow]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Design Your System Message\n",
    "\n",
    "Carefully craft a system message that defines:\n",
    "- The assistant's role\n",
    "- Its expertise area\n",
    "- How it should respond\n",
    "- Any specific behaviors or constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR SYSTEM MESSAGE HERE\n",
    "system_message = \"\"\"\n",
    "YOUR WELL-CRAFTED SYSTEM MESSAGE\n",
    "\"\"\"\n",
    "\n",
    "# Create your conversation\n",
    "my_assistant = Conversation(system_message=system_message)\n",
    "\n",
    "print(\"✓ Assistant created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Demonstrate Your Application\n",
    "\n",
    "Show a realistic conversation with at least 5 turns. Each turn should:\n",
    "- Build on previous context\n",
    "- Demonstrate the assistant's capabilities\n",
    "- Show value to the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn 1\n",
    "print(\"USER: [your message]\")\n",
    "print(\"\\nASSISTANT:\", my_assistant.chat(\"YOUR MESSAGE HERE\"))\n",
    "print(\"\\n\" + \"=\"*70 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn 2\n",
    "print(\"USER: [your follow-up message]\")\n",
    "print(\"\\nASSISTANT:\", my_assistant.chat(\"YOUR FOLLOW-UP HERE\"))\n",
    "print(\"\\n\" + \"=\"*70 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn 3\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn 4\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn 5\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Analyze the Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display full conversation history\n",
    "print(\"FULL CONVERSATION HISTORY:\")\n",
    "print(\"=\"*70)\n",
    "my_assistant.display_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Token usage and cost\n",
    "total_tokens = my_assistant.get_token_count()\n",
    "estimated_cost = (total_tokens / 1_000_000) * 0.60  # Rough estimate for gpt-4o-mini\n",
    "\n",
    "print(f\"Total tokens used: {total_tokens}\")\n",
    "print(f\"Estimated cost: ${estimated_cost:.6f}\")\n",
    "print(f\"Average tokens per turn: {total_tokens / 5:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection Questions\n",
    "\n",
    "### 1. How did the system message shape the conversation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOUR ANSWER HERE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Show an example where context from an earlier turn influenced a later response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOUR ANSWER HERE**\n",
    "\n",
    "Example: In turn [X], I mentioned [Y], and in turn [Z], the assistant referred back to this by [describe how]..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. What would happen if this conversation continued for 20 more turns?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOUR ANSWER HERE**\n",
    "\n",
    "Consider: token costs, context window limits, potential drift from original purpose..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. How could you improve this application?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOUR ANSWER HERE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Challenges (Optional)\n",
    "\n",
    "### Challenge 1: Extend the Conversation Class\n",
    "Add features like:\n",
    "- Saving/loading conversations to file\n",
    "- Automatic summarization when history gets long\n",
    "- Conversation branching\n",
    "- Export to different formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BONUS CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2: Compare Temperature Settings\n",
    "Run the same conversation with different temperatures (0.0, 0.7, 1.2) and compare responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BONUS CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 3: Build a Multi-Persona System\n",
    "Create a system that can switch between different expert personas within a single conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BONUS CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Checklist\n",
    "\n",
    "- [ ] Described your application and its purpose\n",
    "- [ ] Crafted a thoughtful system message\n",
    "- [ ] Demonstrated at least 5 conversation turns\n",
    "- [ ] Showed how context is maintained\n",
    "- [ ] Analyzed token usage and costs\n",
    "- [ ] Answered all reflection questions\n",
    "- [ ] Tested with realistic examples\n",
    "- [ ] Saved your notebook!\n",
    "\n",
    "## Next Week Preview\n",
    "\n",
    "Next week: **Programmatic Prompt Engineering**\n",
    "- Dynamic prompt generation\n",
    "- Template systems\n",
    "- Few-shot learning\n",
    "- Output parsing and validation\n",
    "\n",
    "Start thinking about tasks where you need to generate similar prompts with different data!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
