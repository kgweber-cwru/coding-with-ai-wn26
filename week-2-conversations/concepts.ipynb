{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/kgweber-cwru/coding-with-ai-wn26/blob/main/week-2-conversations/concepts.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2: Building Conversations\n",
    "\n",
    "## Learning Objectives\n",
    "By the end of this session, you will:\n",
    "- Understand how conversation history works\n",
    "- Build multi-turn conversations that maintain context\n",
    "- Use system prompts effectively to shape behavior\n",
    "- Manage conversation length and costs\n",
    "- Handle different roles (system, user, assistant)\n",
    "\n",
    "## Bonus Material:\n",
    "- [Quick reference](markdown_reference.md) for Markdown formatting in PDF and raw Markdown (`markdown_reference.md`) format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    !pip install -q google-genai google-auth python-dotenv seaborn\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "    try:\n",
    "        PROJECT_ID = input(\"Enter your Google Cloud Project ID (press Enter to use default ADC): \").strip()\n",
    "    except Exception:\n",
    "        PROJECT_ID = \"\"\n",
    "    if PROJECT_ID:\n",
    "        os.environ[\"GOOGLE_CLOUD_PROJECT\"] = PROJECT_ID\n",
    "else:\n",
    "    def find_service_account_json(max_up=6):\n",
    "        p = Path.cwd()\n",
    "        for _ in range(max_up):\n",
    "            candidate = p / \"series-2-coding-llms\" / \"creds\"\n",
    "            if candidate.exists():\n",
    "                for f in candidate.glob(\"*.json\"):\n",
    "                    return str(f.resolve())\n",
    "            candidate2 = p / \"creds\"\n",
    "            if candidate2.exists():\n",
    "                for f in candidate2.glob(\"*.json\"):\n",
    "                    return str(f.resolve())\n",
    "            p = p.parent\n",
    "        return None\n",
    "\n",
    "    sa_path = find_service_account_json()\n",
    "    if sa_path:\n",
    "        os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = sa_path\n",
    "    else:\n",
    "        try:\n",
    "            from dotenv import load_dotenv\n",
    "            load_dotenv()\n",
    "        except Exception:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using project: coding-with-ai-wn-26\n",
      "✅ Environment loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import google.auth\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "creds, project = google.auth.default()\n",
    "project = os.environ.get(\"GOOGLE_CLOUD_PROJECT\", project)\n",
    "client = genai.Client(vertexai=True, project=project, location=\"us-central1\")\n",
    "print(f\"Using project: {project}\")\n",
    "\n",
    "print(\"✅ Environment loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Understanding Conversation Structure\n",
    "\n",
    "### The Messages List\n",
    "Conversations are lists of messages exchanged between the user and the model. \n",
    "- **System Instruction**: Sets the behavior/persona (passed separately in configuration)\n",
    "- **User**: The human input\n",
    "- **Model**: The AI response\n",
    "\n",
    "We can track history in a simple list:\n",
    "```python\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Hello!\"},\n",
    "    {\"role\": \"model\", \"content\": \"Hi! How can I help?\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tell me about Python.\"}\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Simple Two-Turn Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: In programming, a **variable** is like a **container** or a **named storage location** in the computer's memory where you can store **data**. This data can be of different types, such as numbers, text, or even more complex structures.\n",
      "\n",
      "Think of it like this:\n",
      "\n",
      "*   **A Box with a Label:** Imagine you have a box. You can put something inside that box (the data). To easily find and access that box later, you put a label on it (the variable name).\n",
      "\n",
      "Here's a breakdown of the key aspects of a variable:\n",
      "\n",
      "1.  **Name:** Every variable has a unique name. This name is how you refer to the variable throughout your code. Good variable names are descriptive and tell you what kind of data the variable holds (e.g., `userName`, `totalScore`, `isLoggedIn`).\n",
      "\n",
      "2.  **Value:** The value is the actual piece of data stored inside the variable. This value can change or be \"varied\" during the execution of your program, which is why it's called a \"variable.\"\n",
      "\n",
      "3.  **Data Type:** In many programming languages, variables have a specific data type. This tells the computer what kind of data the variable is expected to hold and how to interpret it. Common data types include:\n",
      "    *   **Integers:** Whole numbers (e.g., `10`, `-5`, `0`).\n",
      "    *   **Floating-point numbers:** Numbers with decimal points (e.g., `3.14`, `-0.5`, `2.0`).\n",
      "    *   **Strings:** Sequences of characters, usually text (e.g., `\"Hello, world!\"`, `\"Alice\"`).\n",
      "    *   **Booleans:** Represent true or false values (e.g., `true`, `false`).\n",
      "    *   **And many more complex types.**\n",
      "\n",
      "**Why are variables important?**\n",
      "\n",
      "Variables are fundamental to programming because they allow you to:\n",
      "\n",
      "*   **Store and retrieve data:** You can put information into a variable and then use that information later in your program.\n",
      "*   **Manipulate data:** You can perform operations on the data stored in variables, such as calculations, comparisons, or modifications.\n",
      "*   **Make code dynamic:** By changing the values of variables, your program can behave differently and respond to different inputs or conditions.\n",
      "*   **Improve readability:** Well-named variables make your code easier for humans to understand.\n",
      "\n",
      "**Example in a common programming language (Python):**\n",
      "\n",
      "```python\n",
      "# Declaring and initializing a variable named 'age' with an integer value\n",
      "age = 30\n",
      "\n",
      "# Declaring and initializing a variable named 'name' with a string value\n",
      "name = \"Bob\"\n",
      "\n",
      "# Declaring and initializing a variable named 'is_student' with a boolean value\n",
      "is_student = True\n",
      "\n",
      "# You can also change the value of a variable\n",
      "age = 31\n",
      "name = \"Robert\"\n",
      "\n",
      "# You can use variables in expressions\n",
      "message = \"Hello, my name is \" + name + \" and I am \" + str(age) + \" years old.\"\n",
      "\n",
      "print(message)\n",
      "# Output: Hello, my name is Robert and I am 31 years old.\n",
      "```\n",
      "\n",
      "In this Python example:\n",
      "\n",
      "*   `age` is a variable that stores the number `31`.\n",
      "*   `name` is a variable that stores the text `\"Robert\"`.\n",
      "*   `is_student` is a variable that stores the boolean value `True`.\n",
      "\n",
      "Without variables, programs would be very static and much harder to write and manage. They are the building blocks for almost everything you do in programming.\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# System instruction handles the persona\n",
    "system_instruction = \"You are a helpful teaching assistant.\"\n",
    "\n",
    "# Start with first user message\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What is a variable in programming?\"}\n",
    "]\n",
    "\n",
    "# Get first response\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash-lite\",\n",
    "    contents=[types.Content(role=m[\"role\"], parts=[types.Part(text=m[\"content\"])]) for m in messages],\n",
    "    config=types.GenerateContentConfig(system_instruction=system_instruction)\n",
    ")\n",
    "\n",
    "first_answer = response.text\n",
    "print(\"Model:\", first_answer)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "role: user, content: What is a variable in programming?...\n",
      "\n",
      "role: model, content: In programming, a **variable** is like a **contain...\n",
      "\n",
      "role: user, content: Can you give me an example in Python?...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add model's response to history\n",
    "messages.append({\"role\": \"model\", \"content\": first_answer})\n",
    "\n",
    "# Add follow-up question\n",
    "messages.append({\"role\": \"user\", \"content\": \"Can you give me an example in Python?\"})\n",
    "\n",
    "# let's have a look at that messages object now\n",
    "for m in messages:\n",
    "    print(f\"role: {m['role']}, content: {m['content'][0:50]}...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Certainly! Here's an example demonstrating how variables work in Python, covering declaration, assignment, and modification:\n",
      "\n",
      "```python\n",
      "# 1. Declaring and Assigning Values to Variables\n",
      "\n",
      "# A variable to store a name (string)\n",
      "user_name = \"Alice\"\n",
      "\n",
      "# A variable to store an age (integer)\n",
      "user_age = 25\n",
      "\n",
      "# A variable to store a price (floating-point number)\n",
      "item_price = 19.99\n",
      "\n",
      "# A variable to store whether a user is active (boolean)\n",
      "is_active = True\n",
      "\n",
      "# 2. Using Variables\n",
      "\n",
      "# You can print the values stored in variables\n",
      "print(\"User's Name:\", user_name)\n",
      "print(\"User's Age:\", user_age)\n",
      "print(\"Item Price:\", item_price)\n",
      "print(\"Is User Active:\", is_active)\n",
      "\n",
      "# You can also use variables in expressions and operations\n",
      "current_year = 2023\n",
      "birth_year = current_year - user_age\n",
      "print(user_name, \"was born around\", birth_year)\n",
      "\n",
      "# You can combine strings and numbers (you'll need to convert numbers to strings for concatenation)\n",
      "greeting = \"Hello, \" + user_name + \"! You are \" + str(user_age) + \" years old.\"\n",
      "print(greeting)\n",
      "\n",
      "# 3. Modifying Variable Values\n",
      "\n",
      "# You can change the value stored in a variable at any time\n",
      "user_age = user_age + 1  # Increment the age by 1\n",
      "print(\"Happy Birthday! New age:\", user_age)\n",
      "\n",
      "user_name = \"Alicia\"     # Change the name\n",
      "print(\"Your name has been updated to:\", user_name)\n",
      "\n",
      "item_price = item_price * 0.9 # Apply a 10% discount\n",
      "print(\"Discounted price:\", item_price)\n",
      "\n",
      "is_active = False        # Change the boolean status\n",
      "print(\"User is now inactive:\", is_active)\n",
      "\n",
      "# 4. Variables can hold different types of data (Python is dynamically typed)\n",
      "# You can reassign a variable to a different type of data, though it's often good practice to keep them consistent.\n",
      "my_variable = 100       # my_variable is an integer\n",
      "print(\"my_variable is now:\", my_variable, \"and its type is\", type(my_variable))\n",
      "\n",
      "my_variable = \"Hello Python\" # Now my_variable is a string\n",
      "print(\"my_variable is now:\", my_variable, \"and its type is\", type(my_variable))\n",
      "```\n",
      "\n",
      "**Explanation of the Python Example:**\n",
      "\n",
      "1.  **Declaration and Assignment:**\n",
      "    *   We create variables by simply choosing a name (like `user_name`, `user_age`) and using the assignment operator (`=`) to give them an initial value.\n",
      "    *   Python infers the data type automatically (e.g., `\"Alice\"` is a string, `25` is an integer).\n",
      "\n",
      "2.  **Using Variables:**\n",
      "    *   We use the `print()` function to display the values stored in these variables.\n",
      "    *   We perform calculations: `birth_year = current_year - user_age`.\n",
      "    *   We combine variables to form a new string (`greeting`). Notice how `str(user_age)` is used to convert the integer `user_age` into a string so it can be concatenated with other strings.\n",
      "\n",
      "3.  **Modifying Variable Values:**\n",
      "    *   Variables are \"variable\" because their values can change. We demonstrate this by incrementing `user_age`, changing `user_name`, and applying a discount to `item_price`.\n",
      "\n",
      "4.  **Dynamic Typing:**\n",
      "    *   Python is dynamically typed, meaning you don't have to explicitly declare the data type of a variable beforehand.\n",
      "    *   Furthermore, you can reassign a variable to hold data of a completely different type. In the example, `my_variable` starts as an integer and is later reassigned to a string. While flexible, it's generally a good practice to keep the data type consistent for a variable to avoid confusion in your code.\n",
      "\n",
      "This example illustrates the core concept of variables as named containers for data that can be accessed and changed throughout your Python program.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get second response - it remembers context!\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash-lite\",\n",
    "    contents=[types.Content(role=m[\"role\"], parts=[types.Part(text=m[\"content\"])]) for m in messages],\n",
    "    config=types.GenerateContentConfig(system_instruction=system_instruction)\n",
    ")\n",
    "\n",
    "print(\"Model:\", response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Building a Conversation Manager\n",
    "\n",
    "Let's create a helper class to manage conversations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Conversation class created!\n"
     ]
    }
   ],
   "source": [
    "class Conversation:\n",
    "    \"\"\"A simple conversation manager\"\"\"\n",
    "    \n",
    "    def __init__(self, system_message=\"You are a helpful assistant.\", model=\"gemini-2.5-flash-lite\"):\n",
    "        self.system_message = system_message\n",
    "        self.messages = [] # History of user/model turns\n",
    "        self.model = model\n",
    "        self.total_tokens = 0\n",
    "    \n",
    "    def add_user_message(self, content):\n",
    "        \"\"\"Add a user message to the conversation\"\"\"\n",
    "        self.messages.append({\"role\": \"user\", \"content\": content})\n",
    "    \n",
    "    def get_response(self, temperature=0.7, max_tokens=None):\n",
    "        \"\"\"Get assistant response and add to history\"\"\"\n",
    "        # Convert internal message format to Vertex AI Content objects\n",
    "        content_list = [\n",
    "            types.Content(role=m[\"role\"], parts=[types.Part(text=m[\"content\"])]) \n",
    "            for m in self.messages\n",
    "        ]\n",
    "\n",
    "        config = types.GenerateContentConfig(\n",
    "            system_instruction=self.system_message,\n",
    "            temperature=temperature,\n",
    "            max_output_tokens=max_tokens\n",
    "        )\n",
    "        \n",
    "        response = client.models.generate_content(\n",
    "            model=self.model,\n",
    "            contents=content_list,\n",
    "            config=config\n",
    "        )\n",
    "        \n",
    "        model_message = response.text\n",
    "        self.messages.append({\"role\": \"model\", \"content\": model_message})\n",
    "        \n",
    "        if response.usage_metadata:\n",
    "            self.total_tokens += response.usage_metadata.total_token_count\n",
    "        \n",
    "        return model_message\n",
    "    \n",
    "    def chat(self, user_message, temperature=0.7, max_tokens=None):\n",
    "        \"\"\"Convenience method: add user message and get response\"\"\"\n",
    "        self.add_user_message(user_message)\n",
    "        return self.get_response(temperature, max_tokens)\n",
    "    \n",
    "    def display_history(self):\n",
    "        \"\"\"Display the conversation history\"\"\"\n",
    "        print(f\"SYSTEM: {self.system_message}\")\n",
    "        print(\"-\" * 50)\n",
    "        for msg in self.messages:\n",
    "            role = msg[\"role\"].upper()\n",
    "            content = msg[\"content\"]\n",
    "            print(f\"{role}: {content}\")\n",
    "            print(\"-\" * 50)\n",
    "    \n",
    "    def get_token_count(self):\n",
    "        \"\"\"Get total tokens used\"\"\"\n",
    "        return self.total_tokens\n",
    "\n",
    "print(\"✅ Conversation class created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Conversation Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Supervised learning** uses labeled data to train models. Think of it like learning with flashcards: you have questions (inputs) and answers (outputs). The goal is to predict the correct output for new, unseen inputs.\n",
      "\n",
      "**Unsupervised learning** uses unlabeled data. The model tries to find patterns and structures within the data on its own, without any predefined answers. It's like exploring a new dataset and trying to group similar items together or identify anomalies.\n",
      "\n",
      "==================================================\n",
      "\n",
      "You would use **unsupervised learning** for clustering.\n",
      "\n",
      "Clustering is all about finding natural groupings or clusters within unlabeled data, which is exactly what unsupervised learning aims to do.\n",
      "\n",
      "==================================================\n",
      "\n",
      "A popular example algorithm for clustering in unsupervised learning is **K-Means Clustering**.\n",
      "\n",
      "==================================================\n",
      "\n",
      "Total tokens used: 472\n"
     ]
    }
   ],
   "source": [
    "# using time.sleep as a rate limiter to avoid hitting API too quickly in this demo\n",
    "from time import sleep\n",
    "\n",
    "# Create a conversation with a specific persona\n",
    "convo = Conversation(\n",
    "    system_message=\"You are a friendly data science tutor. Keep answers concise but clear.\"\n",
    ")\n",
    "\n",
    "# Have a multi-turn conversation\n",
    "print(convo.chat(\"What's the difference between supervised and unsupervised learning?\"))\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "sleep(6)\n",
    "\n",
    "print(convo.chat(\"Which one would I use for clustering?\"))\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "sleep(6)\n",
    "\n",
    "print(convo.chat(\"Give me an example algorithm for that.\"))\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "print(f\"Total tokens used: {convo.get_token_count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Full Conversation History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYSTEM: You are a friendly data science tutor. Keep answers concise but clear.\n",
      "--------------------------------------------------\n",
      "USER: What's the difference between supervised and unsupervised learning?\n",
      "--------------------------------------------------\n",
      "MODEL: **Supervised learning** uses labeled data to train models. Think of it like learning with flashcards: you have questions (inputs) and answers (outputs). The goal is to predict the correct output for new, unseen inputs.\n",
      "\n",
      "**Unsupervised learning** uses unlabeled data. The model tries to find patterns and structures within the data on its own, without any predefined answers. It's like exploring a new dataset and trying to group similar items together or identify anomalies.\n",
      "--------------------------------------------------\n",
      "USER: Which one would I use for clustering?\n",
      "--------------------------------------------------\n",
      "MODEL: You would use **unsupervised learning** for clustering.\n",
      "\n",
      "Clustering is all about finding natural groupings or clusters within unlabeled data, which is exactly what unsupervised learning aims to do.\n",
      "--------------------------------------------------\n",
      "USER: Give me an example algorithm for that.\n",
      "--------------------------------------------------\n",
      "MODEL: A popular example algorithm for clustering in unsupervised learning is **K-Means Clustering**.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "convo.display_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: System Instruction Strategies\n",
    "\n",
    "The system instruction is powerful! Let's explore different personas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERT:\n",
      "A neural network is a computational model inspired by the structure and function of biological neural networks. It consists of interconnected nodes, or artificial neurons, organized in layers.\n",
      "\n",
      "Key components:\n",
      "\n",
      "*   **Neurons (Nodes):** Basic processing units that receive inputs, apply an activation function, and produce an output.\n",
      "*   **Weights:** Parameters associated with connections between neurons, determining the strength of influence one neuron has on another.\n",
      "*   **Biases:** Additional parameters that shift the activation function's output.\n",
      "*   **Activation Function:** A non-linear function applied to the weighted sum of inputs to introduce non-linearity into the model. Common examples include ReLU, sigmoid, and tanh.\n",
      "*   **Layers:** Neurons are typically organized into layers:\n",
      "    *   **Input Layer:** Receives the raw data.\n",
      "    *   **Hidden Layers:** Perform intermediate computations.\n",
      "    *   **Output Layer:** Produces the final result.\n",
      "\n",
      "**Functionality:**\n",
      "\n",
      "Neural networks learn by adjusting their weights and biases through a process called training. This typically involves:\n",
      "\n",
      "1.  **Forward Propagation:** Input data is passed through the network, layer by layer, to generate an output.\n",
      "2.  **Loss Function:** A measure of the difference between the predicted output and the actual target output.\n",
      "3.  **Backpropagation:** The error is propagated backward through the network to compute gradients of the loss function with respect to each weight and bias.\n",
      "4.  **Optimization:** An optimization algorithm (e.g., gradient descent, Adam) uses these gradients to update the weights and biases, minimizing the loss.\n",
      "\n",
      "**Purpose:**\n",
      "\n",
      "Neural networks are powerful tools for pattern recognition, classification, regression, generation, and other complex machine learning tasks, especially when dealing with large, high-dimensional datasets.\n",
      "\n",
      "==================================================\n",
      "\n",
      "TEACHER:\n",
      "Imagine you have a brand new puppy, and you want to teach it to fetch a ball. How do you do it?\n",
      "\n",
      "You probably don't just tell the puppy once and expect it to understand perfectly. Instead, you:\n",
      "\n",
      "1.  **Show it the ball:** You point to it, maybe even throw it a little.\n",
      "2.  **Encourage it to go towards it:** You might say \"Go get it!\" in an excited voice.\n",
      "3.  **Reward it when it gets closer or picks it up:** You give it a treat, praise it, or pet it.\n",
      "4.  **Correct it if it does something else:** If it wanders off or chews on something else, you might say \"No\" or gently guide it back.\n",
      "\n",
      "You repeat this process many, many times. With each attempt, the puppy gets a little bit better. It starts to understand what \"fetch\" means, what the ball is, and what you want it to do. It's like the puppy's brain is slowly **learning** from its experiences.\n",
      "\n",
      "A **neural network** is kind of like that puppy's brain, but for computers!\n",
      "\n",
      "Instead of teaching a puppy, we're teaching a computer to do a specific task, like:\n",
      "\n",
      "*   **Recognizing pictures:** Is this a picture of a cat or a dog?\n",
      "*   **Translating languages:** Turning English into Spanish.\n",
      "*   **Predicting things:** Will this stock price go up or down?\n",
      "\n",
      "**How does it work, in a super simple way?**\n",
      "\n",
      "Think of the neural network as being made up of many tiny, interconnected \"neurons.\" These neurons are like little decision-makers. They are organized in layers, kind of like a stack of pancakes.\n",
      "\n",
      "*   **Input Layer:** This is where you feed the information into the neural network. For our cat/dog example, the input would be the pixels of the image.\n",
      "*   **Hidden Layers:** These are the \"thinking\" layers in the middle. The neurons in these layers take the information from the previous layer, do some calculations, and pass it on to the next layer. This is where the \"learning\" happens. It's like the puppy trying to figure out what to do.\n",
      "*   **Output Layer:** This is where the neural network gives you its answer. For our example, it would say \"Cat\" or \"Dog.\"\n",
      "\n",
      "**The \"Learning\" Part (like training the puppy):**\n",
      "\n",
      "When we first start, the neural network is not very good at its job. It makes a lot of mistakes, just like the puppy might not fetch the ball correctly at first.\n",
      "\n",
      "So, we show it lots and lots of examples (like showing the puppy the ball many times).\n",
      "\n",
      "*   We show it a picture of a cat and tell it, \"This is a cat.\"\n",
      "*   We show it a picture of a dog and tell it, \"This is a dog.\"\n",
      "\n",
      "When the neural network gets it wrong, we tell it! And just like with the puppy, we adjust the connections between the \"neurons\" inside the network. It's like tweaking the puppy's brain to make it understand better.\n",
      "\n",
      "We do this over and over again, with thousands or even millions of examples. Slowly, the neural network starts to get better and better at its task. The connections between the neurons become stronger for the right answers and weaker for the wrong ones.\n",
      "\n",
      "**In a nutshell:**\n",
      "\n",
      "A neural network is a computer system inspired by the way the human brain works. It's made of interconnected \"neurons\" that learn from data. By showing it many examples and correcting its mistakes, we train it to perform specific tasks, like recognizing patterns or making predictions. It's like teaching a computer through experience, just like you'd teach a puppy!\n"
     ]
    }
   ],
   "source": [
    "# Persona 1: Concise expert\n",
    "expert = Conversation(\n",
    "    system_message=\"You are an expert who gives concise, technical answers. Use precise terminology.\"\n",
    ")\n",
    "\n",
    "# Persona 2: Beginner-friendly teacher\n",
    "teacher = Conversation(\n",
    "    system_message=\"You are a patient teacher explaining concepts to complete beginners. Use analogies and simple language.\"\n",
    ")\n",
    "\n",
    "# Same question to both\n",
    "question = \"What is a neural network?\"\n",
    "\n",
    "print(\"EXPERT:\")\n",
    "print(expert.chat(question))\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "print(\"TEACHER:\")\n",
    "print(teacher.chat(question))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structured Output with System Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.  **DEFINITION:** Hypertension, commonly known as high blood pressure, is a chronic medical condition in which the blood pressure in the arteries is persistently elevated.\n",
      "\n",
      "2.  **KEY POINTS:**\n",
      "    *   Blood pressure is measured in millimeters of mercury (mmHg) and has two numbers: systolic pressure (the top number, representing pressure when the heart beats) and diastolic pressure (the bottom number, representing pressure when the heart rests between beats).\n",
      "    *   Hypertension is generally diagnosed when blood pressure readings are consistently at or above 130/80 mmHg.\n",
      "    *   It often has no symptoms and is sometimes called the \"silent killer\" because damage can occur without people knowing.\n",
      "    *   Uncontrolled hypertension significantly increases the risk of serious health problems like heart disease, stroke, kidney failure, and vision loss.\n",
      "\n",
      "3.  **NOTE:** While lifestyle factors (diet, exercise, weight, stress, alcohol intake) play a significant role, hypertension can also be influenced by genetics, age, and other medical conditions. Regular blood pressure monitoring is crucial for early detection and management.\n",
      "\n",
      "==================================================\n",
      "\n",
      "1.  **DEFINITION:** Hypotension is a medical term for low blood pressure, meaning the pressure of the blood against the artery walls is too low.\n",
      "\n",
      "2.  **KEY POINTS:**\n",
      "    *   Blood pressure readings below 90/60 mmHg are generally considered low.\n",
      "    *   Unlike hypertension, hypotension is often symptomatic, with common signs including dizziness, lightheadedness, fainting, blurred vision, nausea, and fatigue.\n",
      "    *   It can be caused by various factors, such as dehydration, certain medications, heart problems, endocrine issues, severe infection (sepsis), and blood loss.\n",
      "    *   While some people naturally have low blood pressure without ill effects, in others, it can indicate an underlying health problem or lead to inadequate blood flow to vital organs.\n",
      "\n",
      "3.  **NOTE:** It's important to distinguish between occasional, harmless low blood pressure and hypotension that causes symptoms or is a sign of a serious condition. If you experience symptoms of low blood pressure, it's advisable to consult a healthcare professional for proper diagnosis and management.\n"
     ]
    }
   ],
   "source": [
    "# Request specific output format\n",
    "structured = Conversation(\n",
    "    system_message=\"\"\"You are a medical information assistant. \n",
    "    Always structure your responses as:\n",
    "    1. DEFINITION: Brief definition\n",
    "    2. KEY POINTS: 3-4 bullet points\n",
    "    3. NOTE: Important consideration or caution\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "print(structured.chat(\"What is hypertension?\"))\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "print(structured.chat(\"What about hypotension?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Managing Context Window\n",
    "\n",
    "Conversations can get too long! The model has a maximum context window (tokens it can process).\n",
    "\n",
    "### Strategy 1: Keep Recent Messages Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turn 1: Okay, I understand. This is message number 1.\n",
      "\n",
      "Wha...\n",
      "Turn 2: Got it! Message number 2 received.\n",
      "\n",
      "What's next?...\n",
      "Turn 3: Acknowledged. Message number 3 received.\n",
      "\n",
      "What can...\n",
      "Turn 4: Message number 4 received and understood.\n",
      "\n",
      "How can...\n",
      "Turn 5: Message number 5 received.\n",
      "\n",
      "I'm ready for your nex...\n",
      "Turn 6: Message number 6 received and understood.\n",
      "\n",
      "What ca...\n",
      "\n",
      "==================================================\n",
      "\n",
      "Messages in memory: 5\n",
      "\n",
      "Current history:\n",
      "SYSTEM: You are a helpful assistant.\n",
      "--------------------------------------------------\n",
      "MODEL: Message number 4 received and understood.\n",
      "\n",
      "How can I assist you further?\n",
      "--------------------------------------------------\n",
      "USER: This is message number 5\n",
      "--------------------------------------------------\n",
      "MODEL: Message number 5 received.\n",
      "\n",
      "I'm ready for your next request.\n",
      "--------------------------------------------------\n",
      "USER: This is message number 6\n",
      "--------------------------------------------------\n",
      "MODEL: Message number 6 received and understood.\n",
      "\n",
      "What can I do for you now?\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class ConversationWithLimit(Conversation):\n",
    "    \"\"\"Conversation that keeps only recent messages\"\"\"\n",
    "    \n",
    "    def __init__(self, system_message=\"You are a helpful assistant.\", \n",
    "                 model=\"gemini-2.5-flash-lite\", max_history=6):\n",
    "        super().__init__(system_message, model)\n",
    "        self.max_history = max_history  # Keep last N messages\n",
    "    \n",
    "    def get_response(self, temperature=0.7, max_tokens=None):\n",
    "        # Keep only last N messages\n",
    "        if len(self.messages) > self.max_history:\n",
    "            self.messages = self.messages[-self.max_history:]\n",
    "        \n",
    "        return super().get_response(temperature, max_tokens)\n",
    "\n",
    "# Test it\n",
    "limited = ConversationWithLimit(max_history=4)\n",
    "\n",
    "for i in range(6):\n",
    "    response = limited.chat(f\"This is message number {i+1}\")\n",
    "    print(f\"Turn {i+1}: {response[:50]}...\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "print(f\"Messages in memory: {len(limited.messages)}\")\n",
    "print(\"\\nCurrent history:\")\n",
    "limited.display_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy 2: Summarize Old Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The user is sending sequential messages, numbered 5 and 6, to the model. The model acknowledges receipt of each message and indicates its readiness for further instructions.\n"
     ]
    }
   ],
   "source": [
    "def summarize_conversation(messages):\n",
    "    \"\"\"Create a summary of the conversation so far\"\"\"\n",
    "    # Format the conversation text\n",
    "    convo_text = \"\\n\".join([\n",
    "        f\"{msg['role']}: {msg['content']}\" \n",
    "        for msg in messages\n",
    "    ])\n",
    "    \n",
    "    summary_prompt = f\"\"\"Summarize this conversation in 2-3 sentences, \n",
    "    preserving key facts and context:\n",
    "    \n",
    "    {convo_text}\n",
    "    \"\"\"\n",
    "    \n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.5-flash-lite\",\n",
    "        contents=[types.Content(role=\"user\", parts=[types.Part(text=summary_prompt)])],\n",
    "        config=types.GenerateContentConfig(\n",
    "            system_instruction=\"You create concise conversation summaries.\",\n",
    "            temperature=0.3\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return response.text\n",
    "\n",
    "# Test it\n",
    "print(summarize_conversation(limited.messages))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Practical Conversation Applications\n",
    "\n",
    "### Application 1: Q&A Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List comprehensions in Python are a concise and elegant way to create lists. They allow you to build new lists by applying an expression to each item in an existing iterable (like another list, a tuple, or a string), and optionally filtering those items based on a condition.\n",
      "\n",
      "Think of them as a more compact and readable alternative to traditional `for` loops when you're generating lists.\n",
      "\n",
      "Here's the basic syntax:\n",
      "\n",
      "```python\n",
      "new_list = [expression for item in iterable if condition]\n",
      "```\n",
      "\n",
      "Let's break down the components:\n",
      "\n",
      "*   **`expression`**: This is what you want to do with each `item`. It could be the item itself, a transformation of the item, or something else entirely.\n",
      "*   **`for item in iterable`**: This is the loop part. It iterates over each `item` in the `iterable`.\n",
      "*   **`if condition` (optional)**: This is a filter. If the `condition` evaluates to `True` for an `item`, then the `expression` is applied, and the result is added to the `new_list`. If the `condition` is omitted, all items from the `iterable` will be processed.\n",
      "\n",
      "**Let's look at some examples to make this clearer.**\n",
      "\n",
      "Imagine you want to create a list of the squares of numbers from 0 to 9.\n",
      "\n",
      "**Traditional `for` loop approach:**\n",
      "\n",
      "```python\n",
      "squares = []\n",
      "for i in range(10):\n",
      "    squares.append(i**2)\n",
      "print(squares)\n",
      "# Output: [0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n",
      "```\n",
      "\n",
      "**Using a list comprehension:**\n",
      "\n",
      "```python\n",
      "squares = [i**2 for i in range(10)]\n",
      "print(squares)\n",
      "# Output: [0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n",
      "```\n",
      "\n",
      "As you can see, the list comprehension is much shorter and often easier to read for this kind of task.\n",
      "\n",
      "**Example with a condition:**\n",
      "\n",
      "Let's say you want to create a list of only the even numbers from 0 to 9.\n",
      "\n",
      "**Traditional `for` loop approach:**\n",
      "\n",
      "```python\n",
      "even_numbers = []\n",
      "for i in range(10):\n",
      "    if i % 2 == 0:\n",
      "        even_numbers.append(i)\n",
      "print(even_numbers)\n",
      "# Output: [0, 2, 4, 6, 8]\n",
      "```\n",
      "\n",
      "**Using a list comprehension:**\n",
      "\n",
      "```python\n",
      "even_numbers = [i for i in range(10) if i % 2 == 0]\n",
      "print(even_numbers)\n",
      "# Output: [0, 2, 4, 6, 8]\n",
      "```\n",
      "\n",
      "This demonstrates the `if condition` part of the list comprehension.\n",
      "\n",
      "**Key benefits of list comprehensions:**\n",
      "\n",
      "1.  **Conciseness:** They reduce the amount of code needed.\n",
      "2.  **Readability:** For simple list creation and transformation, they can be more readable than equivalent `for` loops.\n",
      "3.  **Performance:** In many cases, list comprehensions can be slightly faster than `for` loops due to optimizations in Python's interpreter.\n",
      "\n",
      "Do you want to see more examples, perhaps with different data types or more complex expressions?\n",
      "\n",
      "==================================================\n",
      "\n",
      "Certainly! Let's dive into an example that specifically highlights the filtering aspect of list comprehensions.\n",
      "\n",
      "Suppose you have a list of strings, and you want to create a new list containing only those strings that have more than 5 characters.\n",
      "\n",
      "**Traditional `for` loop approach with filtering:**\n",
      "\n",
      "```python\n",
      "words = [\"apple\", \"banana\", \"cherry\", \"date\", \"elderberry\", \"fig\"]\n",
      "long_words = []\n",
      "\n",
      "for word in words:\n",
      "    if len(word) > 5:\n",
      "        long_words.append(word)\n",
      "\n",
      "print(long_words)\n",
      "# Output: ['banana', 'cherry', 'elderberry']\n",
      "```\n",
      "\n",
      "**Using a list comprehension with filtering:**\n",
      "\n",
      "```python\n",
      "words = [\"apple\", \"banana\", \"cherry\", \"date\", \"elderberry\", \"fig\"]\n",
      "\n",
      "long_words = [word for word in words if len(word) > 5]\n",
      "\n",
      "print(long_words)\n",
      "# Output: ['banana', 'cherry', 'elderberry']\n",
      "```\n",
      "\n",
      "In this list comprehension:\n",
      "\n",
      "*   **`word`**: This is the `expression`. We want to keep the `word` itself if it meets the condition.\n",
      "*   **`for word in words`**: This is the loop, iterating through each `word` in the `words` list.\n",
      "*   **`if len(word) > 5`**: This is the `condition`. Only if the length of the current `word` is greater than 5 will that `word` be included in the resulting `long_words` list.\n",
      "\n",
      "This is a very common use case for list comprehensions – iterating through a collection and selecting only the items that satisfy a particular criterion.\n",
      "\n",
      "Would you like to try another filtering example, perhaps with numbers and a different type of condition?\n",
      "\n",
      "==================================================\n",
      "\n",
      "That's a great question, and it gets to the heart of why list comprehensions are useful!\n",
      "\n",
      "The core difference lies in **conciseness and structure**, though the underlying logic can be the same.\n",
      "\n",
      "Let's re-examine the example of getting long words:\n",
      "\n",
      "**Regular `for` loop:**\n",
      "\n",
      "```python\n",
      "words = [\"apple\", \"banana\", \"cherry\", \"date\", \"elderberry\", \"fig\"]\n",
      "long_words = [] # 1. Initialize an empty list\n",
      "\n",
      "for word in words: # 2. Start a loop\n",
      "    if len(word) > 5: # 3. Check a condition\n",
      "        long_words.append(word) # 4. If condition met, add to the list\n",
      "\n",
      "print(long_words)\n",
      "```\n",
      "\n",
      "**List comprehension:**\n",
      "\n",
      "```python\n",
      "words = [\"apple\", \"banana\", \"cherry\", \"date\", \"elderberry\", \"fig\"]\n",
      "\n",
      "long_words = [word for word in words if len(word) > 5] # All in one line!\n",
      "\n",
      "print(long_words)\n",
      "```\n",
      "\n",
      "Here's a breakdown of the differences:\n",
      "\n",
      "1.  **Initialization:**\n",
      "    *   **`for` loop:** You **must** explicitly create an empty list (`long_words = []`) before the loop begins.\n",
      "    *   **List comprehension:** The creation of the new list is **implicit**. The square brackets `[]` at the beginning and end signify that a list is being constructed.\n",
      "\n",
      "2.  **Structure and Flow:**\n",
      "    *   **`for` loop:** The process is sequential and spread out: initialize -> loop -> condition -> append. This makes it very explicit step-by-step.\n",
      "    *   **List comprehension:** It condenses these steps into a single, declarative statement. You're essentially *describing* the list you want, rather than *writing* the procedural steps to build it.\n",
      "\n",
      "3.  **Readability (for simple cases):**\n",
      "    *   **`for` loop:** Can be more verbose, but for very complex logic, breaking it down might be clearer.\n",
      "    *   **List comprehension:** For straightforward transformations and filtering, it's often considered more \"Pythonic\" and readable because it expresses the intent more directly. You can see at a glance that you're creating a list based on `words` with a specific filter.\n",
      "\n",
      "4.  **Performance:**\n",
      "    *   While not always a dramatic difference, list comprehensions can sometimes be slightly more performant. This is because Python's interpreter can optimize them more effectively than a general-purpose `for` loop. It avoids some of the overhead associated with repeated `append()` calls.\n",
      "\n",
      "**Think of it like this:**\n",
      "\n",
      "*   A **`for` loop** is like giving someone step-by-step instructions to assemble something.\n",
      "*   A **list comprehension** is like showing them a picture of the finished product and telling them what materials to use.\n",
      "\n",
      "**When might you still prefer a `for` loop?**\n",
      "\n",
      "*   **Complex logic:** If the operations inside the loop are very involved, or if you need to perform multiple actions (like printing intermediate results, breaking out of the loop early based on a condition, or modifying variables outside the list being built), a `for` loop is usually more appropriate.\n",
      "*   **Side effects:** If your loop needs to have side effects (like writing to a file, updating a database, or modifying global variables), a `for` loop is generally clearer. List comprehensions are best for creating a *new* list without significant side effects.\n",
      "*   **Readability for beginners:** For someone just learning Python, the explicit steps of a `for` loop might be easier to grasp initially.\n",
      "\n",
      "In summary, list comprehensions are a syntactic sugar that offers a more compact and often more readable way to create lists from existing iterables, especially when filtering or transforming elements. They don't fundamentally change what's possible, but they change *how* you express it.\n",
      "\n",
      "Does that distinction make sense?\n"
     ]
    }
   ],
   "source": [
    "class QAAssistant:\n",
    "    \"\"\"Interactive Q&A assistant with memory\"\"\"\n",
    "    \n",
    "    def __init__(self, topic=\"general knowledge\"):\n",
    "        system_msg = f\"\"\"You are a knowledgeable assistant specialized in {topic}. \n",
    "        Answer questions clearly and build on previous context in the conversation.\n",
    "        If you don't know something, say so.\"\"\"\n",
    "        self.convo = Conversation(system_message=system_msg)\n",
    "        self.topic = topic\n",
    "    \n",
    "    def ask(self, question):\n",
    "        return self.convo.chat(question)\n",
    "    \n",
    "    def history(self):\n",
    "        self.convo.display_history()\n",
    "\n",
    "# Create a Python programming assistant\n",
    "python_helper = QAAssistant(topic=\"Python programming\")\n",
    "\n",
    "print(python_helper.ask(\"What are list comprehensions?\"))\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "print(python_helper.ask(\"Show me an example with filtering.\"))\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "print(python_helper.ask(\"How is that different from a regular for loop?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application 2: Research Interview Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTERVIEWER: Thank you for sharing that. It's a common experience for many people.\n",
      "\n",
      "Could you tell me a bit more about what prompted you to try telemedicine at that time? Was it a specific health concern, or more of a general shift in how you accessed healthcare?\n",
      "\n",
      "==================================================\n",
      "\n",
      "INTERVIEWER: I understand. Convenience is definitely a major draw for telemedicine.\n",
      "\n",
      "You mentioned missing the \"personal connection.\" Can you describe what that personal connection felt like in an in-person visit, and what felt different or lacking in the telemedicine experience for you?\n",
      "\n",
      "==================================================\n",
      "\n",
      "Interview Summary:\n",
      "The user started using telemedicine during COVID for convenience but missed the personal connection of in-person visits. They elaborated that the convenience was a major draw, and they were asked to describe what they missed about the personal connection and what felt lacking in the telemedicine experience.\n"
     ]
    }
   ],
   "source": [
    "class InterviewAssistant:\n",
    "    \"\"\"Helps conduct and document research interviews\"\"\"\n",
    "    \n",
    "    def __init__(self, research_topic):\n",
    "        system_msg = f\"\"\"You are helping conduct a research interview about {research_topic}.\n",
    "        Your role is to:\n",
    "        1. Ask thoughtful follow-up questions\n",
    "        2. Clarify ambiguous statements\n",
    "        3. Probe for more details when needed\n",
    "        4. Maintain a professional, curious tone\n",
    "        \"\"\"\n",
    "        self.convo = Conversation(system_message=system_msg)\n",
    "        self.topic = research_topic\n",
    "    \n",
    "    def respond(self, interviewee_response):\n",
    "        \"\"\"Process interviewee response and ask follow-up\"\"\"\n",
    "        return self.convo.chat(interviewee_response)\n",
    "    \n",
    "    def get_summary(self):\n",
    "        \"\"\"Get a summary of key points from the interview\"\"\"\n",
    "        return summarize_conversation(self.convo.messages)\n",
    "\n",
    "# Example usage\n",
    "interviewer = InterviewAssistant(\"patient experiences with telemedicine\")\n",
    "\n",
    "print(\"INTERVIEWER:\", interviewer.respond(\"I started using telemedicine during COVID.\"))\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "print(\"INTERVIEWER:\", interviewer.respond(\"It was convenient but I missed the personal connection.\"))\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "print(\"Interview Summary:\")\n",
    "print(interviewer.get_summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application 3: Debugging Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Likely Cause:\n",
      "\n",
      "You're trying to access a key that doesn't exist in the dictionary.\n",
      "\n",
      "### Explanation:\n",
      "\n",
      "Dictionaries in Python store data as key-value pairs. When you use square brackets `[]` with a key inside, Python looks for that specific key in the dictionary. If the key is not found, it raises a `KeyError` because it doesn't know what value to return.\n",
      "\n",
      "In your case, `my_dict` only contains the keys `'name'` and `'age'`. The key `'city'` is not present, hence the `KeyError`.\n",
      "\n",
      "### Suggested Fix:\n",
      "\n",
      "Before accessing a key, you can check if it exists using the `in` operator, or use the `.get()` method which allows you to provide a default value if the key is not found.\n",
      "\n",
      "**Option 1: Using `in` operator**\n",
      "\n",
      "```python\n",
      "my_dict = {'name': 'Alice', 'age': 30}\n",
      "if 'city' in my_dict:\n",
      "    print(my_dict['city'])\n",
      "else:\n",
      "    print(\"City not found in the dictionary.\")\n",
      "```\n",
      "\n",
      "**Option 2: Using `.get()` method**\n",
      "\n",
      "```python\n",
      "my_dict = {'name': 'Alice', 'age': 30}\n",
      "# The second argument to .get() is the default value if the key is not found\n",
      "print(my_dict.get('city', \"City not found\"))\n",
      "```\n",
      "\n",
      "### Clarifying Questions:\n",
      "\n",
      "*   Is there a possibility that `'city'` might be added to the dictionary later in your code?\n",
      "*   What is the expected behavior if the `'city'` key is not present? Do you want to print a message, assign a default value, or handle it in some other way?\n",
      "\n",
      "==================================================\n",
      "\n",
      "You're asking a great question that gets to the heart of robust dictionary handling! There are a couple of primary ways to check if a key exists in a Python dictionary before you try to access it, and each has its own advantages.\n",
      "\n",
      "### 1. Using the `in` Operator (Most Pythonic)\n",
      "\n",
      "This is generally the most recommended and Pythonic way to check for key existence.\n",
      "\n",
      "**How it works:**\n",
      "The `in` operator directly checks if a key is present in the dictionary's keys. It returns `True` if the key exists and `False` otherwise.\n",
      "\n",
      "**Code Example:**\n",
      "\n",
      "```python\n",
      "my_dict = {'name': 'Alice', 'age': 30}\n",
      "\n",
      "if 'name' in my_dict:\n",
      "    print(f\"The name is: {my_dict['name']}\")\n",
      "else:\n",
      "    print(\"The key 'name' does not exist.\")\n",
      "\n",
      "if 'city' in my_dict:\n",
      "    print(f\"The city is: {my_dict['city']}\")\n",
      "else:\n",
      "    print(\"The key 'city' does not exist.\")\n",
      "```\n",
      "\n",
      "**Output:**\n",
      "\n",
      "```\n",
      "The name is: Alice\n",
      "The key 'city' does not exist.\n",
      "```\n",
      "\n",
      "**Why it's good:**\n",
      "*   **Readability:** It's very clear and easy to understand.\n",
      "*   **Efficiency:** It's efficient for checking existence.\n",
      "*   **Directness:** It directly answers the question \"is this key here?\".\n",
      "\n",
      "### 2. Using the `.get()` Method with a Default Value\n",
      "\n",
      "While not strictly a \"check before access\" method in the same way `in` is, the `.get()` method is an excellent alternative for accessing a value when you're not sure if the key exists. It elegantly handles the case where the key might be missing without raising a `KeyError`.\n",
      "\n",
      "**How it works:**\n",
      "The `.get(key, default_value)` method attempts to retrieve the value associated with `key`.\n",
      "*   If `key` is found, it returns its corresponding value.\n",
      "*   If `key` is **not** found, it returns the `default_value` you provide. If you don't provide a `default_value`, it returns `None` by default.\n",
      "\n",
      "**Code Example:**\n",
      "\n",
      "```python\n",
      "my_dict = {'name': 'Alice', 'age': 30}\n",
      "\n",
      "# Accessing a key that exists\n",
      "name = my_dict.get('name', 'N/A') # 'N/A' is the default if 'name' is not found\n",
      "print(f\"Name: {name}\")\n",
      "\n",
      "# Accessing a key that does not exist\n",
      "city = my_dict.get('city', 'Unknown City') # 'Unknown City' will be returned\n",
      "print(f\"City: {city}\")\n",
      "\n",
      "# Accessing a key that does not exist without a specified default (returns None)\n",
      "country = my_dict.get('country')\n",
      "print(f\"Country: {country}\")\n",
      "```\n",
      "\n",
      "**Output:**\n",
      "\n",
      "```\n",
      "Name: Alice\n",
      "City: Unknown City\n",
      "Country: None\n",
      "```\n",
      "\n",
      "**Why it's good:**\n",
      "*   **Conciseness:** It combines checking and retrieving in one step.\n",
      "*   **Graceful Handling:** It avoids `KeyError` exceptions.\n",
      "*   **Flexibility:** You can specify exactly what should happen when a key is missing.\n",
      "\n",
      "### Which one to choose?\n",
      "\n",
      "*   Use the **`in` operator** when you need to perform a specific action *only if* the key exists, or perform different actions based on its presence. It's great for conditional logic.\n",
      "*   Use the **`.get()` method** when you want to retrieve a value and have a sensible fallback (a default value) if the key is not found. It's perfect for situations where you want to avoid `KeyError` and get *something* back, even if it's a placeholder.\n",
      "\n",
      "Both are valuable tools for working with dictionaries safely!\n"
     ]
    }
   ],
   "source": [
    "debugging_assistant = Conversation(\n",
    "    system_message=\"\"\"You are a debugging assistant. When users share code and errors:\n",
    "    1. Identify the likely cause\n",
    "    2. Explain why it's happening\n",
    "    3. Suggest a fix with code\n",
    "    4. Ask clarifying questions if needed\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Simulate debugging session\n",
    "error_report = \"\"\"I'm getting a KeyError in my Python code:\n",
    "my_dict = {'name': 'Alice', 'age': 30}\n",
    "print(my_dict['city'])\n",
    "\"\"\"\n",
    "\n",
    "print(debugging_assistant.chat(error_report))\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "print(debugging_assistant.chat(\"How can I check if a key exists before accessing it?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: New API - built-in chat\n",
    "\n",
    "The latest versions of the Google SDK have a built in chat object that stores history for you. It's still worthwhile to work through this with the hand-built class to be sure you understand what's going on, though. Here's an example of how to use the Google API\n",
    "\n",
    "This is just a wrapper around the `generateContent` tool - it's still sending the entire context back and forth with each step of the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest Response: Absolutely! A multi-part message is where you combine different types of data (like text and an image, or multiple images, etc.) into a single prompt for the model.\n",
      "\n",
      "Here's a common example: sending text along with an image to ask the model a question about that image.\n",
      "\n",
      "First, make sure you have the necessary libraries installed:\n",
      "```bash\n",
      "pip install google-generativeai pillow\n",
      "```\n",
      "\n",
      "Then, you'll need to set up your API key and have an image file ready.\n",
      "\n",
      "```python\n",
      "import google.generativeai as glm\n",
      "import PIL.Image # Pillow library for image handling\n",
      "import os\n",
      "\n",
      "# --- 1. Configure your API Key ---\n",
      "# Make sure you have your API key set up as an environment variable\n",
      "# or replace \"YOUR_API_KEY\" with your actual key.\n",
      "# It's recommended to use environment variables for security.\n",
      "# os.environ[\"GOOGLE_API_KEY\"] = \"YOUR_API_KEY\"\n",
      "glm.configure(api_key=os.environ.get(\"GOOGLE_API_KEY\"))\n",
      "\n",
      "# --- 2. Load the multi-modal model ---\n",
      "# For image input, you need a vision-capable model like 'gemini-pro-vision'\n",
      "model = glm.GenerativeModel(\"gemini-pro-vision\")\n",
      "\n",
      "# --- 3. Prepare your image data ---\n",
      "# Replace 'path/to/your/image.jpg' with the actual path to an image file.\n",
      "# For demonstration, let's create a dummy image if you don't have one handy.\n",
      "try:\n",
      "    img = PIL.Image.open(\"path/to/your/image.jpg\")\n",
      "except FileNotFoundError:\n",
      "    print(\"Image file not found. Creating a dummy image for demonstration.\")\n",
      "    # Create a simple red square image\n",
      "    img = PIL.Image.new('RGB', (200, 200), color = 'red')\n",
      "    # Or, you could fetch one from a URL\n",
      "    # import requests\n",
      "    # from io import BytesIO\n",
      "    # response = requests.get(\"https://www.google.com/images/branding/googlelogo/1x/googlelogo_color_272x92dp.png\")\n",
      "    # img = PIL.Image.open(BytesIO(response.content))\n",
      "\n",
      "\n",
      "# --- 4. Create the 'Part' objects ---\n",
      "# One Part for the text prompt\n",
      "text_part = glm.Part.from_text(\"What's in this picture? Describe it in detail and identify any objects you see.\")\n",
      "\n",
      "# Another Part for the image data\n",
      "image_part = glm.Part.from_image(img) # The SDK converts the PIL Image into a BlobPart\n",
      "\n",
      "\n",
      "# --- 5. Combine the 'Part' objects into a 'Content' object ---\n",
      "# This Content object represents a single \"user turn\" in the conversation,\n",
      "# containing both the text and the image.\n",
      "multi_part_message = glm.Content(\n",
      "    parts=[text_part, image_part],\n",
      "    role=\"user\" # It's good practice to specify the role explicitly\n",
      ")\n",
      "\n",
      "print(\"--- Sending a multi-part message to the model ---\")\n",
      "print(f\"Message parts: {[type(p) for p in multi_part_message.parts]}\")\n",
      "print(f\"Role: {multi_part_message.role}\")\n",
      "# print(multi_part_message) # You can uncomment this to see the raw Content object structure\n",
      "\n",
      "# --- 6. Send the Content object to the model ---\n",
      "try:\n",
      "    response = model.generate_content(multi_part_message)\n",
      "\n",
      "    # --- 7. Print the model's response ---\n",
      "    print(\"\\n--- Model Response ---\")\n",
      "    print(response.text)\n",
      "\n",
      "except Exception as e:\n",
      "    print(f\"\\nAn error occurred: {e}\")\n",
      "    print(\"Please ensure your GOOGLE_API_KEY is correctly set and the image path is valid.\")\n",
      "    print(\"If using a dummy image, ensure it's created successfully.\")\n",
      "\n",
      "```\n",
      "\n",
      "### How it works:\n",
      "\n",
      "1.  **`glm.configure(api_key=...)`**: Initializes the SDK with your API key.\n",
      "2.  **`glm.GenerativeModel(\"gemini-pro-vision\")`**: Instantiates the specific Gemini model capable of handling vision inputs. Regular `gemini-pro` only handles text.\n",
      "3.  **`PIL.Image.open(...)`**: Loads your image file into a Pillow `Image` object, which is a common format the SDK expects.\n",
      "4.  **`glm.Part.from_text(...)`**: Creates a `TextPart` from your string.\n",
      "5.  **`glm.Part.from_image(img)`**: Creates a `BlobPart` (a type of `Part` for binary data) from your Pillow image object. The SDK handles the encoding of the image data internally.\n",
      "6.  **`glm.Content(parts=[text_part, image_part], role=\"user\")`**: This is the core of the multi-part message.\n",
      "    *   We create a `Content` object.\n",
      "    *   The `parts` argument is a *list* containing our previously created `text_part` and `image_part`. The order often matters for the model's interpretation, though for a simple \"describe this image\" it might be flexible.\n",
      "    *   `role=\"user\"` indicates that this `Content` object represents input from the user.\n",
      "7.  **`model.generate_content(multi_part_message)`**: Sends this `Content` object, containing both text and image, to the Gemini model for processing.\n",
      "\n",
      "This example clearly demonstrates how to construct a `Content` object with multiple `Part`s for a multi-modal interaction.\n"
     ]
    }
   ],
   "source": [
    "chat = client.chats.create(model='gemini-2.5-flash')\n",
    "\n",
    "# --- Turn 1 ---\n",
    "chat.send_message(\"Hi, I'm building a project using the Gemini Python SDK.\")\n",
    "\n",
    "# --- Turn 2 ---\n",
    "chat.send_message(\"What is the difference between a 'Content' object and a 'Part'?\")\n",
    "\n",
    "# --- Turn 3 ---\n",
    "response = chat.send_message(\"Can you give me a code example of a multi-part message?\")\n",
    "\n",
    "print(f\"Latest Response: {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the history:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Role: user\n",
      "Text: Hi, I'm building a project using the Gemini Python...\n",
      "--------------------\n",
      "Role: model\n",
      "Text: That's awesome! The Gemini Python SDK is a fantast...\n",
      "--------------------\n",
      "Role: user\n",
      "Text: What is the difference between a 'Content' object ...\n",
      "--------------------\n",
      "Role: model\n",
      "Text: That's a great question, as understanding `Content...\n",
      "--------------------\n",
      "Role: user\n",
      "Text: Can you give me a code example of a multi-part mes...\n",
      "--------------------\n",
      "Role: model\n",
      "Text: Absolutely! A multi-part message is where you comb...\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "for message in chat.get_history():\n",
    "    # Each message is a 'Content' object\n",
    "    print(f\"Role: {message.role}\")\n",
    "    for part in message.parts:\n",
    "        # Each part could be text, inline_data (blobs), or function_calls\n",
    "        if part.text:\n",
    "            print(f\"Text: {part.text[:50]}...\")\n",
    "    print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could manipulate that history and send a trimmed or modified version to a new conversation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_session = [\n",
    "    types.Content(role=\"user\", parts=[types.Part(text=\"My favorite color is Blue.\")]),\n",
    "    types.Content(role=\"model\", parts=[types.Part(text=\"Understood! I will remember that.\")])\n",
    "]\n",
    "\n",
    "# Start a new chat with that memory pre-loaded\n",
    "new_chat = client.chats.create(model='gemini-2.5-flash', history=previous_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Blue\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = new_chat.send_message(\"What is my favorite color?\")\n",
    "print(f\"Response: {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Cost and Performance Considerations\n",
    "\n",
    "By default, every time you call `chat.send_message()` (or send a manually-managed conversation), the SDK sends the **entire accumulated history** back to Google. However, Google has introduced \"Implicit Caching\" which helps under the hood.\n",
    "\n",
    "Here is the breakdown of how the costs and data flow work:\n",
    "\n",
    "### 1. The Standard Flow (Sending History)\n",
    "\n",
    "When you use the `ChatSession` object created by `chats.create()`, the SDK maintains a local list of messages.\n",
    "\n",
    "* **Turn 1:** You send \"Hello\". SDK sends \"Hello\".\n",
    "* **Turn 2:** You send \"How are you?\". SDK sends [\"Hello\", \"Model response\", \"How are you?\"].\n",
    "* **Token Cost:** You are billed for the full length of the history sent in each request.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. How to Actually Manage Costs\n",
    "\n",
    "To save on token costs for long conversations, you have two main options within the Vertex AI ecosystem:\n",
    "\n",
    "#### **Implicit Caching (The \"Automatic\" Way)**\n",
    "\n",
    "As of late 2024/2025, Vertex AI enables **Implicit Caching** by default for most Gemini models.\n",
    "\n",
    "* **How it works:** If you send a large amount of text (usually over **2,048 tokens**) that matches a recent previous request (like a long chat history), Google’s backend may recognize the prefix and serve it from a cache.\n",
    "* **The Benefit:** You often get a **90% discount** on those cached tokens automatically. You don't need to change your code, but you should check the `usage_metadata` in the response to see `cached_content_token_count`.\n",
    "\n",
    "#### **Explicit Context Caching (The \"Manual\" Way)**\n",
    "\n",
    "If you have a massive \"system instruction\" or a set of documents that will stay constant across many different chat sessions, you should use **Explicit Caching**.\n",
    "\n",
    "* You create a cache object using `client.caches.create()`.\n",
    "* This creates a \"TTL\" (Time-To-Live) session on Google's servers.\n",
    "* You then pass that `cache_id` when initializing your chat. This ensures you only pay the \"cached\" rate for that massive block of text.\n",
    "\n",
    "---\n",
    "\n",
    "### Summary Table\n",
    "\n",
    "| Feature | `client.chats.create()` | Implicit Caching | Explicit Caching |\n",
    "| --- | --- | --- | --- |\n",
    "| **Primary Purpose** | Manages `history` list for you | Auto-optimizes repeat prefixes | Manual control for huge contexts |\n",
    "| **Data Sent** | Full history sent every turn | Full history sent (but recognized) | Only new tokens + Cache ID sent |\n",
    "| **Cost Saving** | None (by itself) | **~90% discount** on hits | **~90% discount** guaranteed |\n",
    "| **Best For** | Standard UX / Small history | Short-term repeated turns | System prompts > 2k tokens |\n",
    "\n",
    "### Pro-Tip for Monitoring\n",
    "\n",
    "To see if you are actually saving money, always check the response object:\n",
    "\n",
    "```python\n",
    "response = chat.send_message(\"...\")\n",
    "print(response.usage_metadata.cached_content_token_count)\n",
    "\n",
    "```\n",
    "\n",
    "If that number is greater than 0, Google's server \"remembered\" the previous part of your conversation and discounted your bill for those tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Short conversation (3 turns): 192 tokens\n",
      "Long conversation (10 turns): 1775 tokens\n",
      "\n",
      "Token growth factor: 9.24x\n"
     ]
    }
   ],
   "source": [
    "# See how a conversation grows in tokens as we add more turns\n",
    "\n",
    "short_convo = Conversation()\n",
    "for i in range(3):\n",
    "    short_convo.chat(f\"Write a haiku about the number {i+1}\")\n",
    "\n",
    "long_convo = Conversation()\n",
    "token_count_history = []\n",
    "for i in range(10):\n",
    "    long_convo.chat(f\"Write a haiku about the number {i+1}\")\n",
    "    token_count_history.append(long_convo.get_token_count())\n",
    "\n",
    "print(f\"Short conversation (3 turns): {short_convo.get_token_count()} tokens\")\n",
    "print(f\"Long conversation (10 turns): {long_convo.get_token_count()} tokens\")\n",
    "print(f\"\\nToken growth factor: {long_convo.get_token_count() / short_convo.get_token_count():.2f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "sns.lineplot(x=range(0, 10), y=token_count_history,\n",
    "            ax=ax)\n",
    "\n",
    "ax.set_xlabel(\"Turn Number\")\n",
    "ax.set_ylabel(\"Total Tokens Used\")\n",
    "ax.title.set_text(\"Token Growth Over Conversation Turns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Conversations are message lists** - Just add to the list to maintain context\n",
    "2. **System messages are powerful** - They shape the entire conversation behavior\n",
    "3. **Context grows quickly** - Each turn includes all previous messages\n",
    "4. **Manage conversation length** - Keep recent messages or summarize old ones\n",
    "5. **Structure matters** - Clear roles and formatting help the model respond appropriately\n",
    "\n",
    "## Next Week Preview\n",
    "\n",
    "Next week, we'll explore **programmatic prompt engineering**:\n",
    "- Building dynamic prompts\n",
    "- Template systems\n",
    "- Few-shot learning\n",
    "- Output parsing\n",
    "\n",
    "Complete the assignment to practice building conversational applications!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_seminar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
