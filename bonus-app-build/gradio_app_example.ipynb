{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3365efe",
   "metadata": {},
   "source": [
    "# Build a Simple UI for your AI Application with Gradio\n",
    "\n",
    "This notebook provides a hands-on guide to building a simple web interface for your generative AI applications using Gradio. By the end of this session, you will have a functional web app that interacts with a large language model, and you'll be able to share it with others.\n",
    "\n",
    "**What is Gradio?**\n",
    "\n",
    "Gradio is a Python library that makes it incredibly easy to create simple and interactive UIs for machine learning models and data science projects. It's particularly well-suited for use in environments like Google Colab, where you can run and share your apps with minimal setup.\n",
    "\n",
    "**Learning Objectives:**\n",
    "\n",
    "* Understand the basics of Gradio and its core components.\n",
    "* Learn how to create a simple UI for a function that calls the Gemini API.\n",
    "* See how to launch and share a Gradio app directly from a Colab notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2845424d",
   "metadata": {},
   "source": [
    "## 1. Setup and Authentication\n",
    "\n",
    "First, we need to authenticate to use the Google Cloud services and install the necessary Python libraries. The following cell will:\n",
    "\n",
    "1.  Authenticate you in the Colab environment.\n",
    "2.  Install the `google-generativeai` library to interact with the Gemini API.\n",
    "3.  Install the `gradio` library for building the user interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8fc465e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    !pip install -q google-genai google-auth google-api-core python-dotenv numpy chromadb gradio\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "    try:\n",
    "        PROJECT_ID = input(\"Enter your Google Cloud Project ID (press Enter to use default ADC): \").strip()\n",
    "    except Exception:\n",
    "        PROJECT_ID = \"\"\n",
    "    if PROJECT_ID:\n",
    "        os.environ[\"GOOGLE_CLOUD_PROJECT\"] = PROJECT_ID\n",
    "else:\n",
    "    def find_service_account_json(max_up=6):\n",
    "        p = Path.cwd()\n",
    "        for _ in range(max_up):\n",
    "            candidate = p / \"series-2-coding-llms\" / \"creds\"\n",
    "            if candidate.exists():\n",
    "                for f in candidate.glob(\"*.json\"):\n",
    "                    return str(f.resolve())\n",
    "            candidate2 = p / \"creds\"\n",
    "            if candidate2.exists():\n",
    "                for f in candidate2.glob(\"*.json\"):\n",
    "                    return str(f.resolve())\n",
    "            p = p.parent\n",
    "        return None\n",
    "\n",
    "    sa_path = find_service_account_json()\n",
    "    if sa_path:\n",
    "        os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = sa_path\n",
    "    else:\n",
    "        try:\n",
    "            from dotenv import load_dotenv\n",
    "            load_dotenv()\n",
    "        except Exception:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea28fc7",
   "metadata": {},
   "source": [
    "## 2. Initialize the Generative AI Client\n",
    "\n",
    "Now that we're authenticated and have the libraries installed, we need to set up our project and initialize the client for the Generative AI service. This will allow our application to communicate with the Gemini model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ae5f4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using project: coding-with-ai-wn-26\n",
      "✅ Environment loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "import google.auth\n",
    "from google.api_core import exceptions\n",
    "import gradio as gr\n",
    "\n",
    "creds, project = google.auth.default()\n",
    "project = os.environ.get(\"GOOGLE_CLOUD_PROJECT\", project)\n",
    "client = genai.Client(vertexai=True, project=project, location=\"us-central1\")\n",
    "print(f\"Using project: {project}\")\n",
    "\n",
    "print(\"✅ Environment loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5691b7a",
   "metadata": {},
   "source": [
    "## 3. Create a Function to Interact with the Model\n",
    "\n",
    "This is the core logic of our application. We'll create a Python function that takes a user's prompt as input, sends it to the Gemini model, and returns the model's response. This function will be the backend for our Gradio UI.\n",
    "\n",
    "Of course, this is a primitive little function - you could extend it with any of the tools you've built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f389d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gemini_response(prompt_text):\n",
    "  \"\"\"Sends a prompt to the Gemini model and returns the response.\"\"\"\n",
    "  try:\n",
    "    response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash-lite\",\n",
    "    contents=prompt_text\n",
    "    )\n",
    "\n",
    "    return response.text\n",
    "  except Exception as e:\n",
    "    return f\"An error occurred: {e}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5809ea",
   "metadata": {},
   "source": [
    "## 4. Build and Launch the Gradio Interface\n",
    "\n",
    "Now for the exciting part! We'll use Gradio to create a web interface for our `get_gemini_response` function. With just one line of code, we can create an interface with a textbox for input and a textbox for the output.\n",
    "\n",
    "When you run the cell below, Gradio will create and launch the interface. You'll see it directly in the notebook output, and you'll also get a public URL that you can share with anyone for 72 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c63ab7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iface = gr.Interface(\n",
    "    fn=get_gemini_response, \n",
    "    inputs=gr.Textbox(lines=5, label=\"Your Prompt\"), \n",
    "    outputs=gr.Textbox(label=\"Gemini's Response\"),\n",
    "    title=\"Simple Interface for Gemini\",\n",
    "    description=\"Ask Gemini anything! Enter your prompt below and see the response.\"\n",
    ")\n",
    "\n",
    "iface.launch(debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_seminar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
