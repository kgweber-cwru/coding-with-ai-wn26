{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    !pip install -q google-genai google-auth python-dotenv numpy\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "    try:\n",
    "        PROJECT_ID = input(\"Enter your Google Cloud Project ID (press Enter to use default ADC): \").strip()\n",
    "    except Exception:\n",
    "        PROJECT_ID = \"\"\n",
    "    if PROJECT_ID:\n",
    "        os.environ[\"GOOGLE_CLOUD_PROJECT\"] = PROJECT_ID\n",
    "else:\n",
    "    def find_service_account_json(max_up=6):\n",
    "        p = Path.cwd()\n",
    "        for _ in range(max_up):\n",
    "            candidate = p / \"series-2-coding-llms\" / \"creds\"\n",
    "            if candidate.exists():\n",
    "                for f in candidate.glob(\"*.json\"):\n",
    "                    return str(f.resolve())\n",
    "            candidate2 = p / \"creds\"\n",
    "            if candidate2.exists():\n",
    "                for f in candidate2.glob(\"*.json\"):\n",
    "                    return str(f.resolve())\n",
    "            p = p.parent\n",
    "        return None\n",
    "\n",
    "    sa_path = find_service_account_json()\n",
    "    if sa_path:\n",
    "        os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = sa_path\n",
    "    else:\n",
    "        try:\n",
    "            from dotenv import load_dotenv\n",
    "            load_dotenv()\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "import google.auth\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "creds, project = google.auth.default()\n",
    "project = os.environ.get(\"GOOGLE_CLOUD_PROJECT\", project)\n",
    "client = genai.Client(vertexai=True, project=project, location=\"us-central1\")\n",
    "print(f\"Using project: {project}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/kgweber-cwru/coding-with-ai-wn26/blob/main/week-6-best-practices/assignment.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 6 Assignment: Polish and Present Your Project\n",
    "\n",
    "## Objective\n",
    "Take one of your previous projects (or create a new one) and make it production-ready by adding error handling, testing, cost tracking, and documentation.\n",
    "\n",
    "## Requirements\n",
    "1. Choose or build a complete application\n",
    "2. Add robust error handling\n",
    "3. Implement cost tracking\n",
    "4. Create a test suite\n",
    "5. Write clear documentation\n",
    "6. Prepare a brief presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "import google.auth\n",
    "from google.api_core import exceptions\n",
    "\n",
    "load_dotenv('../.env')\n",
    "creds, project = google.auth.default()\n",
    "client = genai.Client(vertexai=True, project=project, location=\"us-central1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Project Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Your Project Title]\n",
    "\n",
    "## Overview\n",
    "[Brief description of what your application does]\n",
    "\n",
    "## Use Case\n",
    "[Who is this for and what problem does it solve?]\n",
    "\n",
    "## Key Features\n",
    "1. [Feature 1]\n",
    "2. [Feature 2]\n",
    "3. [Feature 3]\n",
    "\n",
    "## Technical Approach\n",
    "[What techniques/patterns are you using?]\n",
    "- Prompt engineering / Conversations / RAG / etc.\n",
    "- Model(s) used\n",
    "- Key design decisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Core Application Code\n",
    "\n",
    "Build or refine your application here. Include comments and clear structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR APPLICATION CODE HERE\n",
    "\n",
    "class YourApplication:\n",
    "    \"\"\"Main application class\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Initialize\n",
    "        pass\n",
    "    \n",
    "    # Add your methods\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Add Error Handling\n",
    "\n",
    "Wrap your API calls with proper error handling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def robust_api_call(contents, max_retries=3, **kwargs):\n",
    "    \"\"\"Make API call with retry logic\"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = client.models.generate_content(\n",
    "                model=kwargs.get('model', 'gemini-2.5-flash-lite'),\n",
    "                contents=contents,\n",
    "                config=types.GenerateContentConfig(\n",
    "                    temperature=kwargs.get('temperature', 0.7),\n",
    "                    max_output_tokens=kwargs.get('max_output_tokens', None)\n",
    "                )\n",
    "            )\n",
    "            return response\n",
    "        except exceptions.ResourceExhausted:\n",
    "            if attempt < max_retries - 1:\n",
    "                wait_time = 2 ** attempt\n",
    "                print(f\"Rate limit. Waiting {wait_time}s...\")\n",
    "                time.sleep(wait_time)\n",
    "            else:\n",
    "                raise\n",
    "        except exceptions.GoogleAPICallError as e:\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(1)\n",
    "            else:\n",
    "                raise\n",
    "    raise Exception(\"Max retries exceeded\")\n",
    "\n",
    "# Integrate this into your application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Add Cost Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CostTracker:\n",
    "    PRICING = {\n",
    "        \"gemini-2.5-flash-lite\": {\"input\": 0.075, \"output\": 0.30},\n",
    "        \"gemini-1.5-pro\": {\"input\": 3.50, \"output\": 10.50},\n",
    "    }\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.total_cost = 0.0\n",
    "        self.calls = []\n",
    "    \n",
    "    def track(self, response, model=\"gemini-2.5-flash-lite\"):\n",
    "        if not response.usage_metadata:\n",
    "            return 0.0\n",
    "            \n",
    "        input_tokens = response.usage_metadata.prompt_token_count\n",
    "        output_tokens = response.usage_metadata.candidates_token_count\n",
    "        \n",
    "        # Default pricing\n",
    "        pricing = self.PRICING.get(model, self.PRICING[\"gemini-2.5-flash-lite\"])\n",
    "        \n",
    "        cost = (\n",
    "            (input_tokens / 1_000_000) * pricing[\"input\"] +\n",
    "            (output_tokens / 1_000_000) * pricing[\"output\"]\n",
    "        )\n",
    "        \n",
    "        self.total_cost += cost\n",
    "        self.calls.append({\"cost\": cost, \"tokens\": input_tokens + output_tokens})\n",
    "        return cost\n",
    "    \n",
    "    def report(self):\n",
    "        return f\"Total cost: ${self.total_cost:.6f} across {len(self.calls)} calls\"\n",
    "\n",
    "# Create tracker and use in your application\n",
    "cost_tracker = CostTracker()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Create Test Suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestSuite:\n",
    "    def __init__(self, app):\n",
    "        self.app = app\n",
    "        self.tests = []\n",
    "        self.results = []\n",
    "    \n",
    "    def add_test(self, name, test_func, expected):\n",
    "        \"\"\"Add a test case\"\"\"\n",
    "        self.tests.append({\n",
    "            \"name\": name,\n",
    "            \"func\": test_func,\n",
    "            \"expected\": expected\n",
    "        })\n",
    "    \n",
    "    def run(self):\n",
    "        \"\"\"Run all tests\"\"\"\n",
    "        print(f\"Running {len(self.tests)} tests...\\n\")\n",
    "        passed = 0\n",
    "        \n",
    "        for test in self.tests:\n",
    "            try:\n",
    "                result = test[\"func\"]()\n",
    "                success = self.check_result(result, test[\"expected\"])\n",
    "                \n",
    "                if success:\n",
    "                    print(f\"✓ {test['name']}\")\n",
    "                    passed += 1\n",
    "                else:\n",
    "                    print(f\"✗ {test['name']}\")\n",
    "                    print(f\"  Expected: {test['expected']}\")\n",
    "                    print(f\"  Got: {result}\")\n",
    "            except Exception as e:\n",
    "                print(f\"✗ {test['name']} - ERROR: {e}\")\n",
    "        \n",
    "        print(f\"\\n{passed}/{len(self.tests)} tests passed\")\n",
    "    \n",
    "    def check_result(self, result, expected):\n",
    "        \"\"\"Check if result meets expectations\"\"\"\n",
    "        if isinstance(expected, list):\n",
    "            # Check if any expected string is in result\n",
    "            return any(exp.lower() in str(result).lower() for exp in expected)\n",
    "        return expected in str(result)\n",
    "\n",
    "# Create and populate test suite\n",
    "# suite = TestSuite(your_app)\n",
    "# suite.add_test(\"Test 1\", lambda: your_app.method(), \"expected output\")\n",
    "# suite.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Define Your Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR TESTS HERE\n",
    "\n",
    "# Example:\n",
    "# def test_basic_functionality():\n",
    "#     result = your_app.main_method(\"test input\")\n",
    "#     return result\n",
    "\n",
    "# suite.add_test(\n",
    "#     \"Basic functionality\",\n",
    "#     test_basic_functionality,\n",
    "#     expected=[\"expected\", \"keywords\"]\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Demonstrate Your Application\n",
    "\n",
    "Show your application working with real examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"APPLICATION DEMONSTRATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Demo 1\n",
    "print(\"\\nExample 1: [Describe what this shows]\")\n",
    "# YOUR DEMO CODE\n",
    "\n",
    "# Demo 2\n",
    "print(\"\\nExample 2: [Describe what this shows]\")\n",
    "# YOUR DEMO CODE\n",
    "\n",
    "# Demo 3\n",
    "print(\"\\nExample 3: [Describe what this shows]\")\n",
    "# YOUR DEMO CODE\n",
    "\n",
    "# Show cost report\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COST REPORT\")\n",
    "print(\"=\"*70)\n",
    "print(cost_tracker.report())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Documentation\n",
    "\n",
    "### User Guide\n",
    "\n",
    "#### How to Use\n",
    "1. [Step 1]\n",
    "2. [Step 2]\n",
    "3. [Step 3]\n",
    "\n",
    "#### Examples\n",
    "```python\n",
    "# Example usage code\n",
    "```\n",
    "\n",
    "### Technical Documentation\n",
    "\n",
    "#### Architecture\n",
    "[Describe how your system is structured]\n",
    "\n",
    "#### Key Components\n",
    "- Component 1: [description]\n",
    "- Component 2: [description]\n",
    "\n",
    "#### API/Methods\n",
    "Document your main methods:\n",
    "- `method_name(param1, param2)`: [what it does]\n",
    "\n",
    "### Known Limitations\n",
    "1. [Limitation 1]\n",
    "2. [Limitation 2]\n",
    "\n",
    "### Future Improvements\n",
    "1. [Improvement 1]\n",
    "2. [Improvement 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Reflection and Analysis\n",
    "\n",
    "### Project Reflection\n",
    "\n",
    "#### What went well?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOUR ANSWER**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What was challenging?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOUR ANSWER**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What did you learn?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOUR ANSWER**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How would you improve this for production?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOUR ANSWER**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What would you build next?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOUR ANSWER**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Presentation Prep\n",
    "\n",
    "Prepare a 5-minute presentation covering:\n",
    "\n",
    "### Slide 1: Title\n",
    "- Project name\n",
    "- Your name\n",
    "- One sentence description\n",
    "\n",
    "### Slide 2: Problem & Solution\n",
    "- What problem does this solve?\n",
    "- Who is it for?\n",
    "- Why LLMs/AI?\n",
    "\n",
    "### Slide 3: Technical Approach\n",
    "- Architecture overview\n",
    "- Key techniques used\n",
    "- Design decisions\n",
    "\n",
    "### Slide 4: Demo\n",
    "- Live demonstration or screenshots\n",
    "- Show key features\n",
    "- Highlight what makes it useful\n",
    "\n",
    "### Slide 5: Results & Next Steps\n",
    "- What worked well?\n",
    "- Metrics (cost, performance, etc.)\n",
    "- Future improvements\n",
    "- Lessons learned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Checklist\n",
    "\n",
    "- [ ] Complete working application\n",
    "- [ ] Error handling implemented\n",
    "- [ ] Cost tracking working\n",
    "- [ ] Test suite created and run\n",
    "- [ ] Clear documentation\n",
    "- [ ] Demonstrations with real examples\n",
    "- [ ] Reflection questions answered\n",
    "- [ ] Presentation prepared\n",
    "- [ ] Code is well-commented\n",
    "- [ ] Ready to present!\n",
    "\n",
    "## Congratulations!\n",
    "\n",
    "You've completed the entire workshop series and built a production-ready LLM application!\n",
    "\n",
    "### What You've Accomplished:\n",
    "- ✓ Mastered LLM API fundamentals\n",
    "- ✓ Built conversational systems\n",
    "- ✓ Created reusable prompt templates\n",
    "- ✓ Implemented semantic search with embeddings\n",
    "- ✓ Built complete RAG systems\n",
    "- ✓ Applied production best practices\n",
    "- ✓ Created a polished, documented application\n",
    "\n",
    "### Keep Building!\n",
    "The field is evolving rapidly. Stay curious, keep experimenting, and share what you create!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
