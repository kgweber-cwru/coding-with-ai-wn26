{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 5: Building Complete RAG Systems\n",
    "\n",
    "## Learning Objectives\n",
    "- Build production-quality RAG pipelines\n",
    "- Implement document chunking strategies\n",
    "- Handle multiple document sources\n",
    "- Improve retrieval quality\n",
    "- Add metadata and filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "import google.auth\n",
    "\n",
    "load_dotenv()\n",
    "creds, project = google.auth.default()\n",
    "client = genai.Client(vertexai=True, project=project, location=\"us-central1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Document Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Document:\n",
    "    \"\"\"Represents a document with metadata\"\"\"\n",
    "    def __init__(self, content, metadata=None):\n",
    "        self.content = content\n",
    "        self.metadata = metadata or {}\n",
    "        self.metadata['created'] = datetime.now().isoformat()\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Document(content={self.content[:50]}..., metadata={self.metadata})\"\n",
    "\n",
    "class DocumentProcessor:\n",
    "    \"\"\"Process and chunk documents\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def chunk_by_sentences(text, chunk_size=3, overlap=1):\n",
    "        \"\"\"Chunk by sentence count\"\"\"\n",
    "        sentences = [s.strip() + '.' for s in text.split('.') if s.strip()]\n",
    "        chunks = []\n",
    "        \n",
    "        for i in range(0, len(sentences), chunk_size - overlap):\n",
    "            chunk = ' '.join(sentences[i:i + chunk_size])\n",
    "            if chunk:\n",
    "                chunks.append(chunk)\n",
    "        \n",
    "        return chunks\n",
    "    \n",
    "    @staticmethod\n",
    "    def chunk_by_words(text, chunk_size=200, overlap=50):\n",
    "        \"\"\"Chunk by word count\"\"\"\n",
    "        words = text.split()\n",
    "        chunks = []\n",
    "        \n",
    "        for i in range(0, len(words), chunk_size - overlap):\n",
    "            chunk = ' '.join(words[i:i + chunk_size])\n",
    "            if chunk:\n",
    "                chunks.append(chunk)\n",
    "        \n",
    "        return chunks\n",
    "\n",
    "print(\"✓ Document classes ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Advanced Document Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGDocumentStore:\n",
    "    \"\"\"Advanced document store with metadata and filtering\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.chunks = []\n",
    "        self.embeddings = []\n",
    "        self.metadata = []\n",
    "    \n",
    "    def add_document(self, document, chunk_strategy='sentences', chunk_size=3):\n",
    "        \"\"\"Add document with chunking\"\"\"\n",
    "        processor = DocumentProcessor()\n",
    "        \n",
    "        if chunk_strategy == 'sentences':\n",
    "            chunks = processor.chunk_by_sentences(document.content, chunk_size)\n",
    "        else:\n",
    "            chunks = processor.chunk_by_words(document.content, chunk_size)\n",
    "        \n",
    "        for i, chunk in enumerate(chunks):\n",
    "            # Get embedding\n",
    "            response = client.models.embed_content(\n",
    "                model=\"text-embedding-004\",\n",
    "                contents=chunk.replace(\"\\n\", \" \")\n",
    "            )\n",
    "            embedding = response.embeddings[0].values\n",
    "            \n",
    "            # Store with metadata\n",
    "            self.chunks.append(chunk)\n",
    "            self.embeddings.append(embedding)\n",
    "            \n",
    "            chunk_metadata = document.metadata.copy()\n",
    "            chunk_metadata['chunk_index'] = i\n",
    "            chunk_metadata['total_chunks'] = len(chunks)\n",
    "            self.metadata.append(chunk_metadata)\n",
    "        \n",
    "        return len(chunks)\n",
    "    \n",
    "    def search(self, query, top_k=5, filters=None):\n",
    "        \"\"\"Search with optional metadata filtering\"\"\"\n",
    "        response = client.models.embed_content(\n",
    "            model=\"text-embedding-004\",\n",
    "            contents=query\n",
    "        )\n",
    "        query_embedding = response.embeddings[0].values\n",
    "        \n",
    "        # Calculate similarities\n",
    "        similarities = []\n",
    "        for i, emb in enumerate(self.embeddings):\n",
    "            # Apply filters\n",
    "            if filters:\n",
    "                skip = False\n",
    "                for key, value in filters.items():\n",
    "                    if key not in self.metadata[i] or self.metadata[i][key] != value:\n",
    "                        skip = True\n",
    "                        break\n",
    "                if skip:\n",
    "                    continue\n",
    "            \n",
    "            sim = np.dot(query_embedding, emb) / (np.linalg.norm(query_embedding) * np.linalg.norm(emb))\n",
    "            similarities.append((i, sim))\n",
    "        \n",
    "        # Sort and get top k\n",
    "        similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_results = similarities[:top_k]\n",
    "        \n",
    "        return [\n",
    "            {\n",
    "                \"chunk\": self.chunks[idx],\n",
    "                \"similarity\": sim,\n",
    "                \"metadata\": self.metadata[idx]\n",
    "            }\n",
    "            for idx, sim in top_results\n",
    "        ]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.chunks)\n",
    "\n",
    "print(\"✓ RAG document store ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Complete RAG System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGSystem:\n",
    "    \"\"\"Complete RAG system\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.store = RAGDocumentStore()\n",
    "    \n",
    "    def add_document(self, content, metadata=None, **kwargs):\n",
    "        \"\"\"Add document to system\"\"\"\n",
    "        doc = Document(content, metadata)\n",
    "        chunks_added = self.store.add_document(doc, **kwargs)\n",
    "        return chunks_added\n",
    "    \n",
    "    def query(self, question, top_k=3, filters=None, temperature=0.3):\n",
    "        \"\"\"Query system with RAG\"\"\"\n",
    "        # Retrieve\n",
    "        results = self.store.search(question, top_k=top_k, filters=filters)\n",
    "        \n",
    "        if not results:\n",
    "            return {\n",
    "                \"answer\": \"No relevant documents found.\",\n",
    "                \"sources\": []\n",
    "            }\n",
    "        \n",
    "        # Build context\n",
    "        context = \"\\n\\n\".join([\n",
    "            f\"[Source {i+1}] {r['chunk']}\"\n",
    "            for i, r in enumerate(results)\n",
    "        ])\n",
    "        \n",
    "        # Generate\n",
    "        prompt = f\"\"\"Answer the question based on the provided context. \n",
    "If the answer is not in the context, say so.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "        \n",
    "        response = client.models.generate_content(\n",
    "            model=\"gemini-1.5-flash\",\n",
    "            contents=prompt,\n",
    "            config=types.GenerateContentConfig(temperature=temperature)\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"answer\": response.text,\n",
    "            \"sources\": results\n",
    "        }\n",
    "    \n",
    "    def stats(self):\n",
    "        \"\"\"Get system statistics\"\"\"\n",
    "        return {\n",
    "            \"total_chunks\": len(self.store),\n",
    "            \"unique_documents\": len(set(m.get('source', '') for m in self.store.metadata))\n",
    "        }\n",
    "\n",
    "print(\"✓ RAG system ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Example - Medical Knowledge Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RAG system\n",
    "rag = RAGSystem()\n",
    "\n",
    "# Add documents with metadata\n",
    "documents = [\n",
    "    {\n",
    "        \"content\": \"\"\"Hypertension, or high blood pressure, is a common condition where blood \n",
    "        pressure is consistently elevated. Treatment includes lifestyle changes like diet and \n",
    "        exercise, and medications such as ACE inhibitors or diuretics. Regular monitoring is essential.\"\"\",\n",
    "        \"metadata\": {\"topic\": \"cardiovascular\", \"source\": \"clinical_guide\", \"date\": \"2024\"}\n",
    "    },\n",
    "    {\n",
    "        \"content\": \"\"\"Type 2 diabetes is characterized by insulin resistance and high blood sugar. \n",
    "        Management includes blood glucose monitoring, dietary modifications, exercise, and medications \n",
    "        like metformin. Complications can affect kidneys, eyes, and nerves if uncontrolled.\"\"\",\n",
    "        \"metadata\": {\"topic\": \"endocrine\", \"source\": \"clinical_guide\", \"date\": \"2024\"}\n",
    "    },\n",
    "    {\n",
    "        \"content\": \"\"\"Asthma is a chronic respiratory condition causing airway inflammation and bronchospasm. \n",
    "        Symptoms include wheezing, shortness of breath, and coughing. Treatment involves inhaled \n",
    "        corticosteroids for prevention and bronchodilators for acute symptoms.\"\"\",\n",
    "        \"metadata\": {\"topic\": \"respiratory\", \"source\": \"clinical_guide\", \"date\": \"2024\"}\n",
    "    }\n",
    "]\n",
    "\n",
    "for doc in documents:\n",
    "    chunks = rag.add_document(doc[\"content\"], doc[\"metadata\"], chunk_strategy='sentences', chunk_size=2)\n",
    "    print(f\"Added document: {chunks} chunks\")\n",
    "\n",
    "print(f\"\\nSystem stats: {rag.stats()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the system\n",
    "questions = [\n",
    "    \"What medications are used to treat high blood pressure?\",\n",
    "    \"How is diabetes managed?\",\n",
    "    \"Tell me about respiratory conditions\"\n",
    "]\n",
    "\n",
    "for q in questions:\n",
    "    print(f\"\\nQ: {q}\")\n",
    "    print(\"=\"*70)\n",
    "    result = rag.query(q, top_k=2)\n",
    "    print(f\"A: {result['answer']}\")\n",
    "    print(\"\\nSources used:\")\n",
    "    for i, src in enumerate(result['sources'], 1):\n",
    "        print(f\"  {i}. [Score: {src['similarity']:.3f}] {src['chunk'][:80]}...\")\n",
    "        print(f\"     Metadata: {src['metadata']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Filtered Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search only cardiovascular topics\n",
    "result = rag.query(\n",
    "    \"What treatments are available?\",\n",
    "    filters={\"topic\": \"cardiovascular\"},\n",
    "    top_k=2\n",
    ")\n",
    "\n",
    "print(\"Filtered to cardiovascular only:\")\n",
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Chunk strategically** - Consider document structure\n",
    "2. **Use metadata** - Filter and organize retrieved content\n",
    "3. **Balance chunk size** - Too small loses context, too large loses precision\n",
    "4. **Track sources** - Always show where information came from\n",
    "5. **Test retrieval quality** - Verify relevant chunks are found\n",
    "\n",
    "## Next Week\n",
    "\n",
    "Best practices and production patterns:\n",
    "- Error handling\n",
    "- Cost optimization\n",
    "- Testing strategies\n",
    "- Deployment considerations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
